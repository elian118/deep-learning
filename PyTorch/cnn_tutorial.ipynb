{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# PyTorch CNN Tutorial\n",
        "## CIFAR-10 Image Classification\n",
        "\n",
        "CIFAR-10 데이터셋을 사용하여 이미지 분류 모델을 구축하고 학습시킵니다.\n",
        "\n",
        "### 목차\n",
        "1. Torch Tensor 기초\n",
        "2. Autograd (자동 미분)\n",
        "3. Torch nn 모듈\n",
        "4. 모델 만들기\n",
        "5. Optimizer와 Loss Function\n",
        "6. 데이터 준비\n",
        "7. 커스텀 데이터셋 클래스\n",
        "8. DataLoader\n",
        "9. Early Stopping\n",
        "10. 학습 및 평가 함수\n",
        "11. 모델 학습 실행\n",
        "12. 테스트\n",
        "13. Pretrained 모델 불러오기\n",
        "14. 전이학습\n",
        "15. 모델 저장 및 불러오기\n",
        "16. 추론 예시\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/user/miniconda3/envs/pytorch_tutorial/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import timm # Torch Image Models\n",
        "\n",
        "import numpy as np\n",
        "from tqdm import tqdm # 진행도바 그려주는 라이브러리\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import copy\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Torch <-> Keras\n",
        "- Torch는 사용할 장비를 골라줘야 함\n",
        "- Keras는 알아서 기본적으로 잡아줌(설정 가능)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available() # NVIDIA GPU + 라이브러리 준비되어 있음 ? True 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.8.0+cpu\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# 디바이스 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Torch Tensor 기초\n",
        "\n",
        "PyTorch의 기본 데이터 구조인 Tensor에 대해 알아봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor_a: tensor([1, 2, 3, 4, 5])\n",
            "tensor_b: tensor([[ 0.4902, -2.3111, -0.6164, -0.8302],\n",
            "        [ 0.1017, -0.0395,  1.7785,  0.3437],\n",
            "        [ 0.6106,  0.7020,  0.5842, -0.1164]])\n",
            "tensor_b shape: torch.Size([3, 4])\n",
            "tensor_c: tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ],
      "source": [
        "# Tensor 생성\n",
        "tensor_a = torch.tensor([1, 2, 3, 4, 5])\n",
        "tensor_b = torch.randn(3, 4) # 3x4 랜덤 텐서\n",
        "tensor_c = torch.zeros(2, 3) # 2x3 영행렬\n",
        "tensor_d = torch.ones(2, 3)  # 2x3 일행렬\n",
        "\n",
        "print(f\"tensor_a: {tensor_a}\")\n",
        "print(f\"tensor_b: {tensor_b}\")\n",
        "print(f\"tensor_b shape: {tensor_b.shape}\")\n",
        "print(f\"tensor_c: {tensor_c}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "덧셈: tensor([5, 7, 9])\n",
            "곱셈(element-wise): tensor([ 4, 10, 18])\n",
            "내적: 32\n"
          ]
        }
      ],
      "source": [
        "# Tensor 연산\n",
        "x = torch.tensor([1, 2, 3])\n",
        "y = torch.tensor([4, 5, 6])\n",
        "\n",
        "# 기본 연산\n",
        "add_result = x + y\n",
        "mul_result = x * y  # element-wise multiplication: 같은 자리끼리 연산. 크기 서로 안 맞으면 알아서 존재하는 자리끼리만 연산해줌\n",
        "matmul_result = torch.matmul(x, y) # mat multiplication(행렬곱 → 수학 행렬곱과 같은 개념) # dot product\n",
        "\n",
        "print(f\"\\n덧셈: {add_result}\")\n",
        "print(f\"곱셈(element-wise): {mul_result}\")\n",
        "print(f\"내적: {matmul_result}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3, 6])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr_a = np.array([1, 2])\n",
        "arr_b = np.array([3])\n",
        "\n",
        "arr_a * arr_b # broadcasting 자동 발생"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "행렬곱 결과 shape: torch.Size([2, 4])\n"
          ]
        }
      ],
      "source": [
        "# 행렬곱\n",
        "matrix_a = torch.randn(2, 3)\n",
        "matrix_b = torch.randn(3, 4)\n",
        "\n",
        "matrix_mul = torch.matmul(matrix_a, matrix_b)\n",
        "print(f\"\\n행렬곱 결과 shape: {matrix_mul.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[[ 2.1374, -0.9100,  0.0826, -1.1602],\n",
            "         [ 1.4240,  0.4190,  1.8029, -0.9022],\n",
            "         [ 1.8094, -1.6589, -1.8107,  0.2419]],\n",
            "\n",
            "        [[ 0.3371, -0.5740,  1.0849,  0.3378],\n",
            "         [ 0.6890,  0.3440,  0.1808,  1.0651],\n",
            "         [ 0.3341, -0.0840,  0.6692, -0.8514]]])\n"
          ]
        }
      ],
      "source": [
        "# Reshape 연산\n",
        "original = torch.randn(2, 3, 4)\n",
        "print(original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Original shape: torch.Size([2, 3, 4]), Reshaped: torch.Size([12, 2])\n"
          ]
        }
      ],
      "source": [
        "# Reshape 연산\n",
        "original = torch.randn(2, 3, 4)\n",
        "reshaped = original.view(12, -1)  # view: reshape과 유사\n",
        "print(f\"\\nOriginal shape: {original.shape}, Reshaped: {reshaped.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Autograd (자동 미분)\n",
        "\n",
        "PyTorch의 자동 미분 시스템에 대해 알아봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# requires_grad=True로 gradient 추적\n",
        "x = torch.tensor([2., 3.], requires_grad=True) # batch가 한번 돌때마다의 학습(계산) 과정 기록 설정\n",
        "y = x ** 2 + 3 * x + 1 # 학습 결과로 가정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2., 3.], requires_grad=True)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11., 19.], grad_fn=<AddBackward0>)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y_sum: 30.0\n",
            "x: tensor([2., 3.], requires_grad=True)\n",
            "y: tensor([11., 19.], grad_fn=<AddBackward0>)\n",
            "dy/dx: tensor([7., 9.])\n"
          ]
        }
      ],
      "source": [
        "# y를 x로 미분\n",
        "y_sum = y.sum()  # requires_grad=True를 통해 계산된 값인 y 에 backward() 실행이 가능하다는 점을 설명하고자 별도 변수를 선언해 더한 값을 할당했을 뿐, 굳이 모든 y를 안 더해도 된다.\n",
        "y_sum.backward() # 각 학습 결과 y의 모든 케이스를 총합 → 미분\n",
        "# print(f\"y_sum: {y_sum}\")\n",
        "\n",
        "print(f\"x: {x}\")\n",
        "print(f\"y: {y}\") # grad_fn=<AddBackward0> → backward() 사용 가능함 표시됨\n",
        "print(f\"dy/dx: {x.grad}\")  # 2*x + 3의 값 → x ** 2 + 3 * x + 1의 미분\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gradient 초기화 후: tensor([0., 0.])\n"
          ]
        }
      ],
      "source": [
        "# Gradient 초기화\n",
        "x.grad.zero_()\n",
        "print(f\"Gradient 초기화 후: {x.grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 파이토치를 활용한 선형 회귀 연습\n",
        "선형 회귀(Linear Regression)는 머신러닝과 통계 분야에서 널리 사용되는 기본적인 예측 기법 중 하나입니다. 선형 회귀의 주된 목적은 데이터 포인트 간의 선형 관계를 파악하는 것입니다. 즉, 주어진 독립 변수(X)를 기반으로 종속 변수(Y)의 값을 예측하는 것입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 데이터 준비\n",
        "선형 회귀를 위한 학습 데이터를 준비합니다.\n",
        "\n",
        "우리가 사용할 데이터는 x와 y 사이에 간단한 선형 관계, y=2x 라는 관계를 가진 데이터를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]]) # 데이터\n",
        "y_train = torch.FloatTensor([[2], [4], [6]]) # 라벨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "print(x_train)\n",
        "print(x_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "print(y_train)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 가중치와 편향 초기화\n",
        "선형 회귀의 목표는 주어진 데이터에 대해 가장 잘 맞는 직선을 찾는 것입니다. 이 직선은 y = Wx + b로 표현될 수 있으며, 여기서\n",
        "\n",
        "\n",
        "**W는 가중치(weight)이고,**\n",
        "\n",
        "\n",
        "**b는 편향(bias)입니다.**\n",
        "\n",
        "\n",
        "데이터 학습을 시작하기 전에, 초기의\n",
        "W와 b 값을 정해줄 필요가 있습니다. 일반적으로는 랜덤 값으로 시작하나, 이 예제에서는 간단히\n",
        "W를 0으로 시작하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.], requires_grad=True)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 업데이트 가능 / 학습가능\n",
        "W = torch.zeros(1, requires_grad=True) # 가중치(기울기)\n",
        "W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1.], requires_grad=True)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b = torch.ones(1, requires_grad=True) # 편향(편차)\n",
        "b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 가설(hypothesis) 설정하기\n",
        "선형 회귀의 핵심은 주어진 x값에 대한 예측값 y를 찾는것 입니다. 이 예측값을 구하기 위해 가설 이라는 함수를 정의합니다 여기서는 간단한 선형 가설을 사용합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[1.2067],\n",
            "        [1.3533],\n",
            "        [1.5000]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 순전파(Forward pass)\n",
        "hypothesis = x_train * W + b # Predictoin(모델의 예측값)\n",
        "print(hypothesis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 비용함수 및 최적화\n",
        "우리의 목표는 주어진 데이터에 가장 잘 맞는 직선을 찾는 것입니다. 이를 위해 실제값과 예측값 사이의 차이를 계산하는 비용 함수를 정의하게 됩니다. 선형 회귀에서는 주로 평균 제곱 오차(Mean Squared Error, MSE)를 비용 함수로 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**평균 제곱 오차(Mean Squared Error)**\n",
        "\n",
        "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n}(\\text{예측값} - \\text{실제값})^2$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**최적화(optimization)**\n",
        "\n",
        "선형 회귀의 학습 과정은 이 비용을 최소화하는 가중치 W와 편향 b를 찾는 것입니다. 이를 위해 경사 하강법(Gradient Descent)와 같은 최적화 알고리즘이 사용됩니다. 파이토치에서는 다양한 최적화 알고리즘을 제공하며, 여기서는 SGD(Stochastic Gradient Descent)를 사용하였습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "예측값 - 실제값: tensor([[-0.7933],\n",
            "        [-2.6467],\n",
            "        [-4.5000]], grad_fn=<SubBackward0>)\n",
            "tensor(9.2947, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 손실 계산\n",
        "cost = torch.mean((hypothesis - y_train) ** 2) # MSE\n",
        "print(f\"예측값 - 실제값: {hypothesis - y_train}\")\n",
        "print(cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0.1467], requires_grad=True), tensor([1.0600], requires_grad=True))"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W, b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 역전파\n",
        "\n",
        "# optimizer 선언 # 최적화 알고리즘 \n",
        "# Optimizer 역할 : 계산된 손실의 기울기(Gradient)를 기반으로 파라미터를 어떻게? 업데이트할지를 알려주는 로직\n",
        "optimizer = torch.optim.SGD((W, b), lr=0.01) # lr = learning rate 변환의 범위\n",
        "# gradient를 0으로 초기화\n",
        "optimizer.zero_grad()\n",
        "# 비용 함수를 미분하여 gradient 계산\n",
        "cost.backward() # W, b에 Gradient가 저장됨\n",
        "# W와 b를 업데이트\n",
        "optimizer.step() # W.grad, b.grad 바탕으로 W, b가 경사하강법에 의해서 업데이트됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0.2772], requires_grad=True), tensor([1.1129], requires_grad=True))"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "W, b # 순전파부터 순서대로 다시 실행하면 출력값이 그때마다 업데이트되고 있음을 확인할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "학습 전\n",
            "weight:tensor([0.], requires_grad=True)\n",
            "Bias:tensor([1.], requires_grad=True)\n",
            "x: tensor([[1.],\n",
            "        [2.],\n",
            "        [3.]]),\n",
            "Label: tensor([[2.],\n",
            "        [4.],\n",
            "        [6.]])\n"
          ]
        }
      ],
      "source": [
        "# 모델 설정\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.ones(1, requires_grad=True)\n",
        "print(\"학습 전\")\n",
        "print(f\"weight:{W}\\nBias:{b}\")\n",
        "print(f\"x: {x_train},\\nLabel: {y_train}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "학습된 가중치(W, b) (tensor([0.9666], requires_grad=True), tensor([1.3761], requires_grad=True)), loss: 1.4161500930786133\n",
            "2\n",
            "학습된 가중치(W, b) (tensor([1.0080], requires_grad=True), tensor([1.3899], requires_grad=True)), loss: 1.1888314485549927\n",
            "3\n",
            "학습된 가중치(W, b) (tensor([1.0450], requires_grad=True), tensor([1.4018], requires_grad=True)), loss: 1.0088139772415161\n",
            "4\n",
            "학습된 가중치(W, b) (tensor([1.0781], requires_grad=True), tensor([1.4120], requires_grad=True)), loss: 0.8661887049674988\n",
            "5\n",
            "학습된 가중치(W, b) (tensor([1.1077], requires_grad=True), tensor([1.4206], requires_grad=True)), loss: 0.7531203627586365\n",
            "6\n",
            "학습된 가중치(W, b) (tensor([1.1341], requires_grad=True), tensor([1.4279], requires_grad=True)), loss: 0.6634175181388855\n",
            "7\n",
            "학습된 가중치(W, b) (tensor([1.1578], requires_grad=True), tensor([1.4340], requires_grad=True)), loss: 0.5921849608421326\n",
            "8\n",
            "학습된 가중치(W, b) (tensor([1.1791], requires_grad=True), tensor([1.4390], requires_grad=True)), loss: 0.5355536341667175\n",
            "9\n",
            "학습된 가중치(W, b) (tensor([1.1981], requires_grad=True), tensor([1.4430], requires_grad=True)), loss: 0.49046579003334045\n",
            "10\n",
            "학습된 가중치(W, b) (tensor([1.2152], requires_grad=True), tensor([1.4462], requires_grad=True)), loss: 0.4545041024684906\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "optimizer = torch.optim.SGD((W, b), lr=0.01)\n",
        "\n",
        "for i in range(epochs):\n",
        "    print(i + 1)\n",
        "    # 순전파\n",
        "    y_pred = x_train * W + b\n",
        "\n",
        "    # 손실 계산\n",
        "    loss = torch.mean((y_pred - y_train) ** 2)\n",
        "\n",
        "    # 옵티마이저 저장된 기울기 초기화\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    # Gradient 계산\n",
        "    loss.backward()\n",
        "\n",
        "    # 업데이트\n",
        "    optimizer.step()\n",
        "    print(f\"학습된 가중치(W, b) {W, b}, loss: {loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Keras <-> Torch\n",
        "- Keras 해당 레이어의 출력물에 대한 형태만 지정\n",
        "  - `Dense(8, input_shape=(input_size,), activation='relu')`\n",
        "  - `Dense(16), activation='relu'`\n",
        "  - `Dense(32), activation='relu'`\n",
        "  - `Dense(10), activation='softmax'`\n",
        "- Torch는 레이어의 입력, 출력값 모두 형태를 지정해줘야 함\n",
        "  - `Linear(inputs, 8)`\n",
        "  - `ReLU()`\n",
        "  - `Linear(8, 16)`\n",
        "  - `ReLU()`\n",
        "  - `Linear(16, 32)`\n",
        "  - `ReLU()`\n",
        "  - `Linear(32, 64)` # 마지막에 softmax는 안 씀"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear(in_features=1, out_features=1, bias=True)\n"
          ]
        }
      ],
      "source": [
        "#  또는 nn module로 선형 회귀\n",
        "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
        "# keras.layer.Dense 역할\n",
        "model = torch.nn.Linear(1, 1) # nn = Nueral Network \n",
        "print(model) # Keras의 model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<generator object Module.parameters at 0x76680caaeb20>\n",
            "[Parameter containing:\n",
            "tensor([[0.4027]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.1118], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "print(model.parameters()) # <generator object Module.parameters at 0x76680caada80> → 형변환해야 볼 수 있음\n",
        "print(list(model.parameters()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 모델학습\n",
        "학습 과정을 살펴 보겠습니다.\n",
        "\n",
        "1. 에포크(Epoch):\n",
        "전체 훈련 데이터가 학습에 한 번 사용된 주기를 말합니다. 여기서는 총 2000번의 에포크(0 ~ 1999) 동안 학습을 수행하도록 설정했습니다.\n",
        "\n",
        "2. 예측(Hypothesis/Prediction):  \n",
        "모델은 입력 x에 가중치 W를 곱하고 편향 b를 더하여 예측값을 계산합니다. 이 예측값은 hypothesis에 저장됩니다.\n",
        "\n",
        "3. 비용 함수(Cost Function):  \n",
        "예측값 hypothesis와 실제값 y_train 간의 오차를 평균 제곱 오차(MSE) 로 계산하여 cost에 저장합니다.\n",
        "\n",
        "4. 최적화(Gradient Descent):  \n",
        "계산된 cost를 바탕으로 경사 하강법을 통해 모델의 가중치 W와 편향 b를 업데이트합니다.\n",
        "\n",
        "5. 로깅(Logging):  \n",
        "학습 진행 상황을 모니터링하기 위해 100 에포크마다 W, b 및 cost 값을 출력합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/2000 Cost: 12.634103\n",
            "Epoch  100/2000 Cost: 0.021725\n",
            "Epoch  200/2000 Cost: 0.013425\n",
            "Epoch  300/2000 Cost: 0.008296\n",
            "Epoch  400/2000 Cost: 0.005126\n",
            "Epoch  500/2000 Cost: 0.003168\n",
            "Epoch  600/2000 Cost: 0.001957\n",
            "Epoch  700/2000 Cost: 0.001210\n",
            "Epoch  800/2000 Cost: 0.000747\n",
            "Epoch  900/2000 Cost: 0.000462\n",
            "Epoch 1000/2000 Cost: 0.000285\n",
            "Epoch 1100/2000 Cost: 0.000176\n",
            "Epoch 1200/2000 Cost: 0.000109\n",
            "Epoch 1300/2000 Cost: 0.000067\n",
            "Epoch 1400/2000 Cost: 0.000042\n",
            "Epoch 1500/2000 Cost: 0.000026\n",
            "Epoch 1600/2000 Cost: 0.000016\n",
            "Epoch 1700/2000 Cost: 0.000010\n",
            "Epoch 1800/2000 Cost: 0.000006\n",
            "Epoch 1900/2000 Cost: 0.000004\n",
            "Epoch 2000/2000 Cost: 0.000002\n"
          ]
        }
      ],
      "source": [
        "nb_epochs = 2000 # EPOCH 학습 횟수\n",
        "\n",
        "# Epoch : 전체 데이터를 1회 완독\n",
        "# 모델이 업데이트 되는 주기는 1 Batch\n",
        "# 일반적으로 1 Epoch != 1 Batch\n",
        "# 우리는 한 Epoch 당 여러 번의 Batch로 분할하여 학습\n",
        "# e.g 데이터 1000개, Batch_size=100이라면 100개짜리 묶음을 10번 순회 > 10번 업데이트\n",
        "# 1 Batch 학습 > 1 Step\n",
        "\n",
        "for epoch in range(nb_epochs + 1):\n",
        "    \n",
        "    # 순전파 → H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = F.mse_loss(prediction, y_train)  # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
        "\n",
        "    # cost로 H(x) 개선하는 부분\n",
        "    # gradient를 0으로 초기화\n",
        "    optimizer.zero_grad()\n",
        "    # 비용 함수를 미분하여 gradient 계산\n",
        "    cost.backward()\n",
        "    # W와 b를 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        # 100번마다 로그 출력\n",
        "        print(\"Epoch {:4d}/{} Cost: {:.6f}\".format(epoch, nb_epochs, cost.item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 모델 추론\n",
        "학습된 모델을 사용하여 새로운 데이터에 대한 예측을 수행해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9970]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# 임의의 입력 4를 선언\n",
        "new_var = torch.FloatTensor([[4.0]])\n",
        "\n",
        "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
        "pred_y = model(new_var)  # forward 연산\n",
        "\n",
        "# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것\n",
        "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이 예제에서는 y = 2x 관계를 가지는 데이터로 모델을 학습시켰기 때문에, 입력값이 4일 때 예측값은 8에 가까운 값이 출력되어야 합니다. 이를 통해 모델이 정상적으로 학습되었음을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 모델 파라미터 확인\n",
        "PyTorch의 model.parameters() 메서드를 사용하면, 해당 모델의 모든 파라미터(가중치와 편향)를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[1.9982]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0040], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "# list(model.parameters())\n",
        "for _ in model.parameters():\n",
        "    print(_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Torch nn 모듈\n",
        "\n",
        "PyTorch의 신경망 모듈에 대해 알아봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conv2d layer: Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "Linear layer: Linear(in_features=128, out_features=10, bias=True)\n"
          ]
        }
      ],
      "source": [
        "# 레이어 선언\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
        "# kernel size - 1 만큼 덜 이동\n",
        "linear_layer = nn.Linear(in_features=128, out_features=10)\n",
        "relu = nn.ReLU() # Rectified Linear Unit의 줄임말\n",
        "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "print(f\"Conv2d layer: {conv_layer}\")\n",
        "print(f\"Linear layer: {linear_layer}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Channel 위치\n",
        "- Keras: `MNIST (28, 28, 1)` → Channel-last (B, H, W, C) 방식\n",
        "- PyTorch: `MNIST (1, 28, 28)` → Channel-first (B, C, H, W) 방식"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "입력 shape: torch.Size([1, 3, 32, 32])\n",
            "Conv 출력 shape: torch.Size([1, 16, 32, 32])\n"
          ]
        }
      ],
      "source": [
        "# 더미 텐서로 레이어 테스트\n",
        "dummy_image = torch.randn(1, 3, 32, 32)  # Batch=1, Channel=3, Height=32, Width=32\n",
        "conv_output = conv_layer(dummy_image)\n",
        "print(f\"\\n입력 shape: {dummy_image.shape}\")\n",
        "print(f\"Conv 출력 shape: {conv_output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 용어 정리\n",
        "- Layer(층): 노드와 노드 사이에서 계산을 실행하는 계층\n",
        "- 노드: 한 층을 통과(계산)한 후 결과를 취합한 각각의 집합\n",
        "- 커널: 이미지의 특징을 추출하는 작은 행렬 형태의 가중치 묶음을 의미. 종종 **필터(Filter)**와 같은 의미로 사용\n",
        "  - 3x3이 현재 가장 추천되는 커널 사이즈로 굳혀졌다.\n",
        "  - 커널 사이즈와 커널 수는 다른 개념이며, 한 번에 묶여서 실행되는 커널의 수가 커널 수가 된다.\n",
        "- CNN에서 특징별로 컨볼루션 필터가 featured maps를 만들고<br/>이를 특징마다 반복하며 최종 취합해 flatten layer를 만드는 일련의 과정을 backborn(척추), 이후 과정을 head(뇌)라고도 부른다.<br/>\n",
        "    backborn은 이미지를 이해하는 과정, head는 학습 과정이다.\n",
        "- 필터의 갯수는 관심갖는 필터링 대상(특징)만큼 늘어나며, out_channels가 곧 필터의 갯수다.\n",
        "- 필터마다 다가가는 갖는 정답이 다르므로, 여기에서 점차 도출해가는 최적의 가중치 또한 각각 다른 경우의 수가 나온다.\n",
        "- [참고](https://velog.io/@groovallstar/cnn)\n",
        "\n",
        "#### 퀴즈 - Conv2d layer에서 학습 가능한 매개변수 총 개수는 몇이 될까? (stride=1 기준)\n",
        "- 가중치 수\n",
        "$$\\text{Weight Count} = \\text{in\\_channels} \\times \\text{out\\_channels} \\times \\text{kernel\\_size} \\times \\text{kernel\\_size}$$\n",
        "-  편향수: 편향은 출력 채널의 개수만큼 존재\n",
        "$$\\text{Bias Count} = \\text{out\\_channels}$$\n",
        "- 총 학습 가능한 매개변수(Parameters)의 개수|\n",
        "    ```\n",
        "    Conv2d layer: Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
        "    # (3 * 3 * 3 * 16) + 16 = 448\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Conv layer의 파라미터:\n",
            "  weight: shape=torch.Size([16, 3, 3, 3]), requires_grad=True\n",
            "  bias: shape=torch.Size([16]), requires_grad=True\n"
          ]
        }
      ],
      "source": [
        "# 파라미터 확인\n",
        "print(f\"\\nConv layer의 파라미터:\")\n",
        "for name, param in conv_layer.named_parameters():\n",
        "    print(f\"  {name}: shape={param.shape}, requires_grad={param.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "학습 전 weight requires_grad: True\n",
            "학습 방지 후 weight requires_grad: True\n"
          ]
        }
      ],
      "source": [
        "# no_grad로 학습 방지\n",
        "print(f\"\\n학습 전 weight requires_grad: {conv_layer.weight.requires_grad}\")\n",
        "for params in conv_layer.parameters():\n",
        "    param.requires_grad = False\n",
        "print(f\"학습 방지 후 weight requires_grad: {conv_layer.weight.requires_grad}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "다시 학습 가능하게 설정 후 weight requires_grad: True\n"
          ]
        }
      ],
      "source": [
        "# 다시 학습 가능하게 설정\n",
        "for params in conv_layer.parameters():\n",
        "    param.requires_grad = True\n",
        "print(f\"다시 학습 가능하게 설정 후 weight requires_grad: {conv_layer.weight.requires_grad}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 모델 만들기\n",
        "\n",
        "CNN 모델을 만드는 두 가지 방법을 알아봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 방법 1: Sequential\n",
        "sequential_model = nn.Sequential(                   # (3, 32, 32) 가정\n",
        "    nn.Conv2d(3, 32, kernel_size=3, padding=1),     # (32, 32, 32)\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),                                # (32, 16, 16)\n",
        "    nn.Conv2d(32, 64, kernel_size=3, padding=1),    # (64, 16, 16)\n",
        "    nn.ReLU(),\n",
        "    nn.MaxPool2d(2),                                # (64, 8, 8)\n",
        "    nn.Flatten(),                                   # (64 * 8 * 8)\n",
        "    nn.Linear(64 * 8 * 8, 128),                     # (128,) # 1차원\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(128, 10)                              # (10,)\n",
        ")\n",
        "\n",
        "print(sequential_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Subclassing Model:\n",
            "CNNModel(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 방법 2: Subclassing (권장)\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(CNNModel, self).__init__()\n",
        "        \n",
        "        # Convolutional layers # (3 x 32 x 32)\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)     # (32, 32, 32) → nn.MaxPool2d(2, 2) → (32, 16, 16)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)    # (64, 16, 16) → nn.MaxPool2d(2, 2) → (64, 8, 8)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)   # (128, 8, 8) → nn.MaxPool2d(2, 2) → (128, 4, 4)\n",
        "        \n",
        "        # Pooling\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "        \n",
        "        # Dropout\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Conv block 1 Conv → ReLU → Max Pool\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # 32x32 -> 16x16\n",
        "        \n",
        "        # Conv block 2\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 16x16 -> 8x8\n",
        "        \n",
        "        # Conv block 3\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # 8x8 -> 4x4\n",
        "        \n",
        "        # Flatten → 배치 사이즈는 유지하고 나머지는 펴기\n",
        "        x.view(x.size(0), -1) # Batch, 128, 4, 4\n",
        "        \n",
        "        # FC layers → ReLU → Dropout → FC\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "model = CNNModel(num_classes=10)\n",
        "print(f\"\\nSubclassing Model:\\n{model}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "전체 파라미터: 620,362\n",
            "학습 가능한 파라미터: 620,362\n"
          ]
        }
      ],
      "source": [
        "# 모델 파라미터 수 계산\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\n전체 파라미터: {total_params:,}\")\n",
        "print(f\"학습 가능한 파라미터: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. 순전파\n",
        "    - 데이터\n",
        "    - 모델\n",
        "2. 손실계산\n",
        "    - 손실함수\n",
        "    - 정답\n",
        "3. 역전파\n",
        "    - optimizer\n",
        "\n",
        "만약 일반적인 이미지(jpg, jpeg, png, svg, webp)를 다운받는다면? → 모델에 입력 불가\n",
        "\n",
        "Type -> torch.tensor\n",
        "크기 -> Resizing # 모델의 준비된 파라미터에 맞게 재조정\n",
        "정제 -> 정규화(Normalization/Scaling)\n",
        "오버피팅 방지 -> 증강(Augmentation)\n",
        "\n",
        "이미지/텍스트/오디오 서로 성격 다르므로 전처리 기법이 다름\n",
        "torch 각 모달리티를 위한 라이브러리를 제공함\n",
        "- torchvision\n",
        "- torchtexst (X 업데이트 중단. 허깅페이스에서 제공)\n",
        "- torchaudio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Optimizer와 Loss Function\n",
        "\n",
        "학습에 필요한 최적화 알고리즘과 손실 함수에 대해 알아봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SGD optimizer: SGD (\n",
            "Parameter Group 0\n",
            "    dampening: 0\n",
            "    differentiable: False\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    momentum: 0.9\n",
            "    nesterov: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "Adam optimizer: Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Optimizer 설정\n",
        "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # 1e-2\n",
        "optimizer_adam = optim.Adam(model.parameters(), lr=0.01)\n",
        "optimizer_adamw = optim.AdamW(model.parameters(), lr=0.01) # 크기가 큰 모델에서 사용 Transformer, Diffusion 학습법(크기가 큰 데서 사용)\n",
        "\n",
        "print(f\"SGD optimizer: {optimizer_sgd}\")\n",
        "print(f\"Adam optimizer: {optimizer_adam}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "CrossEntropyLoss: CrossEntropyLoss()\n"
          ]
        }
      ],
      "source": [
        "# Loss function\n",
        "criterion_ce = nn.CrossEntropyLoss() # sparse categorical 같은 것 없음 / Softmax 포함되어 있음\n",
        "criterion_mse = nn.MSELoss()\n",
        "\n",
        "print(f\"\\nCrossEntropyLoss: {criterion_ce}\")\n",
        "\n",
        "# Optimizer 사용 예시\n",
        "optimizer = optimizer_adam  # Adam 사용\n",
        "criterion = criterion_ce\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 데이터 준비 - CIFAR-10\n",
        "\n",
        "CIFAR-10 데이터셋을 다운로드하고 전처리합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transform 정의\n",
        "transform_train = transforms.Compose([\n",
        "    # 증강기법들(Augumentation)\n",
        "    transforms.RandomCrop(32, padding=4),   # 무작위 자르기 및 확대\n",
        "    transforms.RandomHorizontalFlip(),      # 무작위 좌우 대칭\n",
        "    # 모델에 입력하기 위한 정제 과정\n",
        "    transforms.ToTensor(),                  # PIL.Image -> torch.tensor 형식으로 변환\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))    # (R, G, B) 표준정규화 \n",
        "    # 표준화 공식: (x - 평균) / 표준편차\n",
        "])\n",
        "\n",
        "# 테스트 단계에서는 증강 과정 불필요\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CIFAR-10 다운로드\n",
        "full_train_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', \n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform_train\n",
        ")\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', \n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform_test\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torchvision.datasets.cifar.CIFAR10"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(full_train_dataset) # sklearn.model_selection.train_test_split 사용 불가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 데이터 분할: Train/Validation\n",
        "train_size = int(0.8 * len(full_train_dataset))\n",
        "val_size = len(full_train_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Validation dataset에 test transform 적용\n",
        "val_dataset.dataset.transform = transform_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train dataset size: 40000\n",
            "Validation dataset size: 10000\n",
            "Test dataset size: 10000\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 클래스 이름\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 커스텀 데이터셋 클래스 예시\n",
        "\n",
        "커스텀 데이터셋을 만드는 방법을 알아봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomCIFAR10(Dataset):\n",
        "    \"\"\"\n",
        "    커스텀 데이터셋 클래스 예시\n",
        "    실제로는 위의 torchvision.datasets.CIFAR10을 사용하지만,\n",
        "    커스텀 데이터셋을 만드는 방법을 보여주기 위한 예시입니다.\n",
        "    \"\"\"\n",
        "    def __init__(self, data, targets, transform=None):\n",
        "        self.data = data\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.data[idx]\n",
        "        label = self.targets[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. DataLoader\n",
        "\n",
        "데이터를 배치 단위로 로드하는 DataLoader를 설정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size=batch_size,\n",
        "    shuffle=True, \n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    # YOUR CODE HERE\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    # YOUR CODE HERE\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Validation batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 샘플 배치 확인\n",
        "sample_batch = # YOUR CODE HERE\n",
        "sample_images, sample_labels = # YOUR CODE HERE\n",
        "print(f\"\\nSample batch - Images shape: {sample_images.shape}\")\n",
        "print(f\"Sample batch - Labels shape: {sample_labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 학습 및 평가 함수\n",
        "\n",
        "모델 학습과 평가를 위한 함수들을 정의합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    \"\"\"한 에포크 학습\"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(loader, desc='Training')\n",
        "    for images, labels in pbar:\n",
        "        # YOUR CODE HERE\n",
        "        \n",
        "        # Forward pass\n",
        "        # YOUR CODE HERE\n",
        "        \n",
        "        # Backward pass\n",
        "        # YOUR CODE HERE\n",
        "        \n",
        "        # 통계\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "        \n",
        "        # 프로그레스 바 업데이트\n",
        "        pbar.set_postfix({\n",
        "            'loss': f'{running_loss / (pbar.n + 1):.4f}',\n",
        "            'acc': f'{100. * correct / total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_epoch(model, loader, criterion, device):\n",
        "    \"\"\"한 에포크 검증\"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(loader, desc='Validation')\n",
        "        for images, labels in pbar:\n",
        "            # YOUR CODE HERE\n",
        "            \n",
        "            outputs = # YOUR CODE HERE\n",
        "            loss = # YOUR CODE HERE\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            \n",
        "            pbar.set_postfix({\n",
        "                'loss': f'{running_loss / (pbar.n + 1):.4f}',\n",
        "                'acc': f'{100. * correct / total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    epoch_loss = running_loss / len(loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
        "                num_epochs, device, best_model_path='best_model.pth'):\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'train_acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "    \n",
        "    best_val_loss = float('inf')\n",
        "    best_model_wts = None\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 50)\n",
        "        \n",
        "        # 학습\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        \n",
        "        # 검증\n",
        "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
        "        \n",
        "        # 히스토리 저장\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        \n",
        "        # best val_loss 모델 저장\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model_wts = model.state_dict()\n",
        "            torch.save(best_model_wts, best_model_path)\n",
        "            print(f'>> Best model saved! val_loss: {val_loss:.4f}')\n",
        "        \n",
        "        # 결과 출력\n",
        "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
        "        \n",
        "    return history\n",
        "\n",
        "print(\"전체 학습 루프 함수 정의 완료\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 모델 학습 실행\n",
        "\n",
        "CNN 모델을 학습시킵니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 초기화\n",
        "model = # YOUR CODE HERE\n",
        "\n",
        "# Optimizer와 Loss\n",
        "optimizer = # YOUR CODE HERE\n",
        "criterion = # YOUR CODE HERE\n",
        "\n",
        "\n",
        "# 학습 실행\n",
        "num_epochs = 20\n",
        "history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=num_epochs,\n",
        "    device=device,\n",
        "    best_model_path='best_model.pth'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 학습 곡선 시각화\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Loss\n",
        "axes[0].plot(history['train_loss'], label='Train Loss')\n",
        "axes[0].plot(history['val_loss'], label='Val Loss')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].set_title('Training and Validation Loss')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True)\n",
        "\n",
        "# Accuracy\n",
        "axes[1].plot(history['train_acc'], label='Train Acc')\n",
        "axes[1].plot(history['val_acc'], label='Val Acc')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy (%)')\n",
        "axes[1].set_title('Training and Validation Accuracy')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "print(\"Training history saved to 'training_history.png'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 테스트\n",
        "\n",
        "학습된 모델을 테스트 데이터로 평가합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# best model을 불러오는 코드\n",
        "best_model = torch.load('best_model.pth', map_location=device)\n",
        "model.load_state_dict(best_model)\n",
        "print(\"Best model loaded from 'best_model.pth'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(model, test_loader, device):\n",
        "    \"\"\"테스트 데이터로 모델 평가\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    # 클래스별 정확도 계산을 위한 변수\n",
        "    class_correct = list(0. for i in range(10))\n",
        "    class_total = list(0. for i in range(10))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc='Testing'):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            \n",
        "            # 클래스별 정확도\n",
        "            c = (predicted == labels).squeeze()\n",
        "            for i in range(len(labels)):\n",
        "                label = labels[i]\n",
        "                class_correct[label] += c[i].item()\n",
        "                class_total[label] += 1\n",
        "    \n",
        "    # 전체 정확도\n",
        "    accuracy = 100. * correct / total\n",
        "    print(f'\\nTest Accuracy: {accuracy:.2f}%')\n",
        "    \n",
        "    # 클래스별 정확도\n",
        "    print('\\nClass-wise Accuracy:')\n",
        "    for i in range(10):\n",
        "        class_acc = 100 * class_correct[i] / class_total[i]\n",
        "        print(f'{classes[i]:>10s}: {class_acc:.2f}%')\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "test_accuracy = test_model(model, test_loader, device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Pretrained 모델 불러오기\n",
        "\n",
        "사전 훈련된 모델을 불러오는 방법을 알아봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torchvision에서 모델 불러오기\n",
        "print(\"[torchvision models]\")\n",
        "resnet18 = # YOUR CODE HERE\n",
        "print(f\"ResNet18 loaded: {type(resnet18)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 마지막 레이어 수정 (CIFAR-10은 10개 클래스)\n",
        "num_features = # YOUR CODE HERE\n",
        "resnet18.fc = # YOUR CODE HERE\n",
        "print(f\"Modified final layer for 10 classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# timm에서 모델 불러오기\n",
        "print(\"\\n[timm models]\")\n",
        "efficientnet = timm.create_model('efficientnet_b0', pretrained=True, num_classes=10)\n",
        "print(f\"EfficientNet-B0 loaded: {type(efficientnet)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# timm에서 사용 가능한 모델 확인 (처음 10개만)\n",
        "available_models = timm.list_models(pretrained=True)[:10]\n",
        "print(f\"\\nAvailable pretrained models (first 10): {available_models}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. 전이학습 (Transfer Learning)\n",
        "\n",
        "사전 훈련된 모델을 활용한 전이학습 방법을 알아봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ResNet18로 전이학습 예시\n",
        "model_transfer = models.resnet18(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 방법 1: 모든 레이어 동결 (Feature Extractor로 사용)\n",
        "print(\"[방법 1] Feature Extractor - 모든 레이어 동결\")\n",
        "for param in model_transfer.parameters():\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "# 마지막 레이어만 학습 가능하게 설정\n",
        "num_features = model_transfer.fc.in_features\n",
        "model_transfer.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "# 학습 가능한 파라미터만 optimizer에 전달\n",
        "optimizer_transfer = optim.Adam(model_transfer.fc.parameters(), lr=0.001)\n",
        "\n",
        "trainable_params_1 = sum(p.numel() for p in model_transfer.parameters() if p.requires_grad)\n",
        "print(f\"학습 가능한 파라미터 수: {trainable_params_1:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 방법 2: 일부 레이어만 학습 (Fine-tuning)\n",
        "print(\"\\n[방법 2] Fine-tuning - 마지막 몇 개 레이어만 학습\")\n",
        "model_transfer2 = models.resnet18(pretrained=True)\n",
        "\n",
        "# 처음 레이어들은 동결\n",
        "for name, param in model_transfer2.named_parameters():\n",
        "    if 'layer4' not in name and 'fc' not in name:\n",
        "        param.requires_grad = # YOUR CODE HERE\n",
        "\n",
        "# 마지막 레이어 수정\n",
        "model_transfer2.fc = # YOUR CODE HERE\n",
        "\n",
        "# 학습 가능한 파라미터만 optimizer에 전달\n",
        "optimizer_transfer2 = optim.Adam(\n",
        "    filter(lambda p: p.requires_grad, model_transfer2.parameters()), \n",
        "    lr=0.001\n",
        ")\n",
        "\n",
        "trainable_params_2 = sum(p.numel() for p in model_transfer2.parameters() if p.requires_grad)\n",
        "print(f\"학습 가능한 파라미터 수: {trainable_params_2:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 방법 3: 전체 모델 Fine-tuning (작은 learning rate 사용)\n",
        "print(\"\\n[방법 3] Full Fine-tuning - 전체 모델 학습 (작은 LR)\")\n",
        "model_transfer3 = models.resnet18(pretrained=True)\n",
        "model_transfer3.fc = nn.Linear(model_transfer3.fc.in_features, 10)\n",
        "\n",
        "# Differential learning rate: Backbone은 작은 LR, 새 레이어는 큰 LR\n",
        "optimizer_transfer3 = optim.Adam([\n",
        "    {'params': model_transfer3.layer4.parameters(), 'lr': 1e-4},\n",
        "    {'params': model_transfer3.fc.parameters(), 'lr': 1e-3}\n",
        "])\n",
        "\n",
        "print(f\"Backbone LR: 1e-4, New layer LR: 1e-3\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 전이학습 모델로 간단히 학습 (3 에포크만)\n",
        "print(\"\\n전이학습 모델 학습 시작 (3 epochs)...\")\n",
        "model_transfer = model_transfer.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(3):\n",
        "    print(f'\\nEpoch {epoch+1}/3')\n",
        "    train_loss, train_acc = train_epoch(\n",
        "        model_transfer, train_loader, criterion, optimizer_transfer, device\n",
        "    )\n",
        "    val_loss, val_acc = validate_epoch(\n",
        "        model_transfer, val_loader, criterion, device\n",
        "    )\n",
        "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. 모델 저장 및 불러오기\n",
        "\n",
        "학습된 모델을 저장하고 불러오는 방법을 알아봅니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 모델 저장\n",
        "torch.save(model.state_dict(), 'cifar10_cnn_model.pth')\n",
        "print(\"모델 가중치 저장 완료: cifar10_cnn_model.pth\")\n",
        "\n",
        "# 전체 모델 저장 (권장하지 않음, 하지만 가능함)\n",
        "torch.save(model, 'cifar10_cnn_full_model.pth')\n",
        "print(\"전체 모델 저장 완료: cifar10_cnn_full_model.pth\")\n",
        "\n",
        "# 모델 불러오기\n",
        "loaded_model = CNNModel(num_classes=10)\n",
        "loaded_model.load_state_dict(torch.load('cifar10_cnn_model.pth'))\n",
        "loaded_model = loaded_model.to(device)\n",
        "loaded_model.eval()\n",
        "print(\"\\n모델 가중치 불러오기 완료\")\n",
        "\n",
        "# 체크포인트 저장 (optimizer 상태 포함)\n",
        "checkpoint = {\n",
        "    'epoch': num_epochs,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'history': history\n",
        "}\n",
        "torch.save(checkpoint, 'checkpoint.pth')\n",
        "print(\"체크포인트 저장 완료: checkpoint.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16. 추론 예시\n",
        "\n",
        "학습된 모델을 사용하여 새로운 이미지에 대한 예측을 수행합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 테스트 이미지 하나 가져오기\n",
        "sample_image, sample_label = test_dataset[0]\n",
        "sample_image_batch = sample_image.unsqueeze(0).to(device)  # 배치 차원 추가\n",
        "\n",
        "# 추론\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(sample_image_batch)\n",
        "    probabilities = F.softmax(output, dim=1)\n",
        "    predicted_class = output.argmax(dim=1).item()\n",
        "    confidence = probabilities[0][predicted_class].item()\n",
        "\n",
        "print(f\"실제 클래스: {classes[sample_label]}\")\n",
        "print(f\"예측 클래스: {classes[predicted_class]}\")\n",
        "print(f\"신뢰도: {confidence * 100:.2f}%\")\n",
        "\n",
        "# Top-5 예측\n",
        "top5_prob, top5_classes = torch.topk(probabilities, 5)\n",
        "print(\"\\nTop-5 예측:\")\n",
        "for i in range(5):\n",
        "    print(f\"{i+1}. {classes[top5_classes[0][i]]}: {top5_prob[0][i].item() * 100:.2f}%\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch_tutorial",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
