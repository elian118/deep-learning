{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch CNN Tutorial\n",
    "## CIFAR-10 Image Classification\n",
    "\n",
    "CIFAR-10 데이터셋을 사용하여 이미지 분류 모델을 구축하고 학습시킵니다.\n",
    "\n",
    "### 목차\n",
    "1. Torch Tensor 기초\n",
    "2. Autograd (자동 미분)\n",
    "3. Torch nn 모듈\n",
    "4. 모델 만들기\n",
    "5. Optimizer와 Loss Function\n",
    "6. 데이터 준비\n",
    "7. 커스텀 데이터셋 클래스\n",
    "8. DataLoader\n",
    "9. Early Stopping\n",
    "10. 학습 및 평가 함수\n",
    "11. 모델 학습 실행\n",
    "12. 테스트\n",
    "13. Pretrained 모델 불러오기\n",
    "14. 전이학습\n",
    "15. 모델 저장 및 불러오기\n",
    "16. 추론 예시\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:54.882167Z",
     "start_time": "2025-11-06T11:18:48.248282Z"
    }
   },
   "source": [
    "# 필요한 라이브러리 import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import timm # Torch Image Models\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm # 진행도바 그려주는 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import copy\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elian\\miniconda3\\envs\\pytorch_tutorial\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch <-> Keras\n",
    "- Torch는 사용할 장비를 골라줘야 함\n",
    "- Keras는 알아서 기본적으로 잡아줌(설정 가능)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:54.902416Z",
     "start_time": "2025-11-06T11:18:54.893436Z"
    }
   },
   "source": [
    "torch.cuda.is_available() # NVIDIA GPU + 라이브러리 준비되어 있음 ? True 반환"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:54.930446Z",
     "start_time": "2025-11-06T11:18:54.924959Z"
    }
   },
   "source": [
    "# 디바이스 설정\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Using device: {device}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cpu\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Torch Tensor 기초\n",
    "\n",
    "PyTorch의 기본 데이터 구조인 Tensor에 대해 알아봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:54.969570Z",
     "start_time": "2025-11-06T11:18:54.958132Z"
    }
   },
   "source": [
    "# Tensor 생성\n",
    "tensor_a = torch.tensor([1, 2, 3, 4, 5])\n",
    "tensor_b = torch.randn(3, 4) # 3x4 랜덤 텐서\n",
    "tensor_c = torch.zeros(2, 3) # 2x3 영행렬\n",
    "tensor_d = torch.ones(2, 3)  # 2x3 일행렬\n",
    "\n",
    "print(f\"tensor_a: {tensor_a}\")\n",
    "print(f\"tensor_b: {tensor_b}\")\n",
    "print(f\"tensor_b shape: {tensor_b.shape}\")\n",
    "print(f\"tensor_c: {tensor_c}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_a: tensor([1, 2, 3, 4, 5])\n",
      "tensor_b: tensor([[ 1.3162, -0.7122,  0.0290, -0.1100],\n",
      "        [ 0.6137,  0.5627, -0.3838,  0.3156],\n",
      "        [ 1.2234,  0.5709,  0.0106, -1.1837]])\n",
      "tensor_b shape: torch.Size([3, 4])\n",
      "tensor_c: tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.005536Z",
     "start_time": "2025-11-06T11:18:54.997962Z"
    }
   },
   "source": [
    "# Tensor 연산\n",
    "x = torch.tensor([1, 2, 3])\n",
    "y = torch.tensor([4, 5, 6])\n",
    "\n",
    "# 기본 연산\n",
    "add_result = x + y\n",
    "mul_result = x * y  # element-wise multiplication: 같은 자리끼리 연산. 크기 서로 안 맞으면 알아서 존재하는 자리끼리만 연산해줌\n",
    "matmul_result = torch.matmul(x, y) # mat multiplication(행렬곱 → 수학 행렬곱과 같은 개념) # dot product\n",
    "\n",
    "print(f\"\\n덧셈: {add_result}\")\n",
    "print(f\"곱셈(element-wise): {mul_result}\")\n",
    "print(f\"내적: {matmul_result}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "덧셈: tensor([5, 7, 9])\n",
      "곱셈(element-wise): tensor([ 4, 10, 18])\n",
      "내적: 32\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.024365Z",
     "start_time": "2025-11-06T11:18:55.018111Z"
    }
   },
   "source": [
    "arr_a = np.array([1, 2])\n",
    "arr_b = np.array([3])\n",
    "\n",
    "arr_a * arr_b # broadcasting 자동 발생"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 6])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.067871Z",
     "start_time": "2025-11-06T11:18:55.063206Z"
    }
   },
   "source": [
    "# 행렬곱\n",
    "matrix_a = torch.randn(2, 3)\n",
    "matrix_b = torch.randn(3, 4)\n",
    "\n",
    "matrix_mul = torch.matmul(matrix_a, matrix_b)\n",
    "print(f\"\\n행렬곱 결과 shape: {matrix_mul.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "행렬곱 결과 shape: torch.Size([2, 4])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.102009Z",
     "start_time": "2025-11-06T11:18:55.096209Z"
    }
   },
   "source": [
    "# Reshape 연산\n",
    "original = torch.randn(2, 3, 4)\n",
    "print(original)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9556,  1.4983, -0.3174, -2.2848],\n",
      "         [-1.3016, -1.3514,  1.6740, -0.2719],\n",
      "         [ 2.0960,  0.7196, -0.0108, -1.3713]],\n",
      "\n",
      "        [[ 0.3213,  0.7023,  1.2937, -0.3703],\n",
      "         [-0.7419,  1.7632,  1.2735,  0.8286],\n",
      "         [ 1.0223,  1.1304,  0.5855, -2.4043]]])\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.135448Z",
     "start_time": "2025-11-06T11:18:55.129027Z"
    }
   },
   "source": [
    "# Reshape 연산\n",
    "original = torch.randn(2, 3, 4)\n",
    "reshaped = original.view(12, -1)  # view: reshape과 유사\n",
    "print(f\"\\nOriginal shape: {original.shape}, Reshaped: {reshaped.shape}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original shape: torch.Size([2, 3, 4]), Reshaped: torch.Size([12, 2])\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Autograd (자동 미분)\n",
    "\n",
    "PyTorch의 자동 미분 시스템에 대해 알아봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.166059Z",
     "start_time": "2025-11-06T11:18:55.159871Z"
    }
   },
   "source": [
    "# requires_grad=True로 gradient 추적\n",
    "x = torch.tensor([2., 3.], requires_grad=True) # batch가 한번 돌때마다의 학습(계산) 과정 기록 설정\n",
    "y = x ** 2 + 3 * x + 1 # 학습 결과로 가정"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.185149Z",
     "start_time": "2025-11-06T11:18:55.179052Z"
    }
   },
   "source": [
    "x"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.203483Z",
     "start_time": "2025-11-06T11:18:55.196187Z"
    }
   },
   "source": [
    "y"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11., 19.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.250459Z",
     "start_time": "2025-11-06T11:18:55.241932Z"
    }
   },
   "source": [
    "# y를 x로 미분\n",
    "y_sum = y.sum()  # requires_grad=True를 통해 계산된 값인 y 에 backward() 실행이 가능하다는 점을 설명하고자 별도 변수를 선언해 더한 값을 할당했을 뿐, 굳이 모든 y를 안 더해도 된다.\n",
    "y_sum.backward() # 각 학습 결과 y의 모든 케이스를 총합 → 미분\n",
    "# print(f\"y_sum: {y_sum}\")\n",
    "\n",
    "print(f\"x: {x}\")\n",
    "print(f\"y: {y}\") # grad_fn=<AddBackward0> → backward() 사용 가능함 표시됨\n",
    "print(f\"dy/dx: {x.grad}\")  # 2*x + 3의 값 → x ** 2 + 3 * x + 1의 미분\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([2., 3.], requires_grad=True)\n",
      "y: tensor([11., 19.], grad_fn=<AddBackward0>)\n",
      "dy/dx: tensor([7., 9.])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.281828Z",
     "start_time": "2025-11-06T11:18:55.276129Z"
    }
   },
   "source": [
    "# Gradient 초기화\n",
    "x.grad.zero_()\n",
    "print(f\"Gradient 초기화 후: {x.grad}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient 초기화 후: tensor([0., 0.])\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파이토치를 활용한 선형 회귀 연습\n",
    "선형 회귀(Linear Regression)는 머신러닝과 통계 분야에서 널리 사용되는 기본적인 예측 기법 중 하나입니다. 선형 회귀의 주된 목적은 데이터 포인트 간의 선형 관계를 파악하는 것입니다. 즉, 주어진 독립 변수(X)를 기반으로 종속 변수(Y)의 값을 예측하는 것입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비\n",
    "선형 회귀를 위한 학습 데이터를 준비합니다.\n",
    "\n",
    "우리가 사용할 데이터는 x와 y 사이에 간단한 선형 관계, y=2x 라는 관계를 가진 데이터를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.315492Z",
     "start_time": "2025-11-06T11:18:55.309596Z"
    }
   },
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]]) # 데이터\n",
    "y_train = torch.FloatTensor([[2], [4], [6]]) # 라벨"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.336014Z",
     "start_time": "2025-11-06T11:18:55.330748Z"
    }
   },
   "source": [
    "print(x_train)\n",
    "print(x_train.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.373640Z",
     "start_time": "2025-11-06T11:18:55.367684Z"
    }
   },
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.],\n",
      "        [4.],\n",
      "        [6.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치와 편향 초기화\n",
    "선형 회귀의 목표는 주어진 데이터에 대해 가장 잘 맞는 직선을 찾는 것입니다. 이 직선은 y = Wx + b로 표현될 수 있으며, 여기서\n",
    "\n",
    "\n",
    "**W는 가중치(weight)이고,**\n",
    "\n",
    "\n",
    "**b는 편향(bias)입니다.**\n",
    "\n",
    "\n",
    "데이터 학습을 시작하기 전에, 초기의\n",
    "W와 b 값을 정해줄 필요가 있습니다. 일반적으로는 랜덤 값으로 시작하나, 이 예제에서는 간단히\n",
    "W를 0으로 시작하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.416081Z",
     "start_time": "2025-11-06T11:18:55.409558Z"
    }
   },
   "source": [
    "# 업데이트 가능 / 학습가능\n",
    "W = torch.zeros(1, requires_grad=True) # 가중치(기울기)\n",
    "W"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.453112Z",
     "start_time": "2025-11-06T11:18:55.446809Z"
    }
   },
   "source": [
    "b = torch.ones(1, requires_grad=True) # 편향(편차)\n",
    "b"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가설(hypothesis) 설정하기\n",
    "선형 회귀의 핵심은 주어진 x값에 대한 예측값 y를 찾는것 입니다. 이 예측값을 구하기 위해 가설 이라는 함수를 정의합니다 여기서는 간단한 선형 가설을 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.485382Z",
     "start_time": "2025-11-06T11:18:55.480550Z"
    }
   },
   "source": [
    "# 순전파(Forward pass)\n",
    "hypothesis = x_train * W + b # Prediction(모델의 예측값)\n",
    "print(hypothesis)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [1.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 비용함수 및 최적화\n",
    "우리의 목표는 주어진 데이터에 가장 잘 맞는 직선을 찾는 것입니다. 이를 위해 실제값과 예측값 사이의 차이를 계산하는 비용 함수를 정의하게 됩니다. 선형 회귀에서는 주로 평균 제곱 오차(Mean Squared Error, MSE)를 비용 함수로 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**평균 제곱 오차(Mean Squared Error)**\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n}(\\text{예측값} - \\text{실제값})^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**최적화(optimization)**\n",
    "\n",
    "선형 회귀의 학습 과정은 이 비용을 최소화하는 가중치 W와 편향 b를 찾는 것입니다. 이를 위해 경사 하강법(Gradient Descent)와 같은 최적화 알고리즘이 사용됩니다. 파이토치에서는 다양한 최적화 알고리즘을 제공하며, 여기서는 SGD(Stochastic Gradient Descent)를 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.519582Z",
     "start_time": "2025-11-06T11:18:55.512881Z"
    }
   },
   "source": [
    "# 손실 계산\n",
    "cost = torch.mean((hypothesis - y_train) ** 2) # MSE\n",
    "print(f\"예측값 - 실제값: {hypothesis - y_train}\")\n",
    "print(cost)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측값 - 실제값: tensor([[-1.],\n",
      "        [-3.],\n",
      "        [-5.]], grad_fn=<SubBackward0>)\n",
      "tensor(11.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.552795Z",
     "start_time": "2025-11-06T11:18:55.545772Z"
    }
   },
   "source": [
    "W, b"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.], requires_grad=True), tensor([1.], requires_grad=True))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.586374Z",
     "start_time": "2025-11-06T11:18:55.578842Z"
    }
   },
   "source": [
    "# 역전파\n",
    "\n",
    "# optimizer 선언 # 최적화 알고리즘 \n",
    "# Optimizer 역할 : 계산된 손실의 기울기(Gradient)를 기반으로 파라미터를 어떻게? 업데이트할지를 알려주는 로직\n",
    "optimizer = torch.optim.SGD((W, b), lr=0.01) # lr = learning rate 변환의 범위\n",
    "# gradient를 0으로 초기화\n",
    "optimizer.zero_grad()\n",
    "# 비용 함수를 미분하여 gradient 계산\n",
    "cost.backward() # W, b에 Gradient가 저장됨\n",
    "# W와 b를 업데이트\n",
    "optimizer.step() # W.grad, b.grad 바탕으로 W, b가 경사하강법에 의해서 업데이트됨"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.604578Z",
     "start_time": "2025-11-06T11:18:55.598470Z"
    }
   },
   "source": [
    "W, b # 순전파부터 순서대로 다시 실행하면 출력값이 그때마다 업데이트되고 있음을 확인할 수 있다."
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1467], requires_grad=True), tensor([1.0600], requires_grad=True))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.625562Z",
     "start_time": "2025-11-06T11:18:55.618035Z"
    }
   },
   "source": [
    "# 모델 설정\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.ones(1, requires_grad=True)\n",
    "print(\"학습 전\")\n",
    "print(f\"weight:{W}\\nBias:{b}\")\n",
    "print(f\"x: {x_train},\\nLabel: {y_train}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 전\n",
      "weight:tensor([0.], requires_grad=True)\n",
      "Bias:tensor([1.], requires_grad=True)\n",
      "x: tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]]),\n",
      "Label: tensor([[2.],\n",
      "        [4.],\n",
      "        [6.]])\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.681331Z",
     "start_time": "2025-11-06T11:18:55.661793Z"
    }
   },
   "source": [
    "epochs = 10\n",
    "optimizer = torch.optim.SGD((W, b), lr=0.01)\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(i + 1)\n",
    "    # 순전파\n",
    "    y_pred = x_train * W + b\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = torch.mean((y_pred - y_train) ** 2)\n",
    "\n",
    "    # 옵티마이저 저장된 기울기 초기화\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Gradient 계산\n",
    "    loss.backward()\n",
    "\n",
    "    # 업데이트\n",
    "    optimizer.step()\n",
    "    print(f\"학습된 가중치(W, b) {W, b}, loss: {loss}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "학습된 가중치(W, b) (tensor([0.1467], requires_grad=True), tensor([1.0600], requires_grad=True)), loss: 11.666666984558105\n",
      "2\n",
      "학습된 가중치(W, b) (tensor([0.2772], requires_grad=True), tensor([1.1129], requires_grad=True)), loss: 9.2947416305542\n",
      "3\n",
      "학습된 가중치(W, b) (tensor([0.3935], requires_grad=True), tensor([1.1596], requires_grad=True)), loss: 7.4195098876953125\n",
      "4\n",
      "학습된 가중치(W, b) (tensor([0.4971], requires_grad=True), tensor([1.2007], requires_grad=True)), loss: 5.936893463134766\n",
      "5\n",
      "학습된 가중치(W, b) (tensor([0.5893], requires_grad=True), tensor([1.2368], requires_grad=True)), loss: 4.7646164894104\n",
      "6\n",
      "학습된 가중치(W, b) (tensor([0.6715], requires_grad=True), tensor([1.2684], requires_grad=True)), loss: 3.83764910697937\n",
      "7\n",
      "학습된 가중치(W, b) (tensor([0.7448], requires_grad=True), tensor([1.2962], requires_grad=True)), loss: 3.104588508605957\n",
      "8\n",
      "학습된 가중치(W, b) (tensor([0.8101], requires_grad=True), tensor([1.3205], requires_grad=True)), loss: 2.52480149269104\n",
      "9\n",
      "학습된 가중치(W, b) (tensor([0.8683], requires_grad=True), tensor([1.3417], requires_grad=True)), loss: 2.0661706924438477\n",
      "10\n",
      "학습된 가중치(W, b) (tensor([0.9203], requires_grad=True), tensor([1.3601], requires_grad=True)), loss: 1.703309416770935\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras ↔ Torch\n",
    "- Keras 해당 레이어의 출력물에 대한 형태만 지정\n",
    "  - `Dense(8, input_shape=(input_size,), activation='relu')`\n",
    "  - `Dense(16), activation='relu'`\n",
    "  - `Dense(32), activation='relu'`\n",
    "  - `Dense(10), activation='softmax'`\n",
    "- Torch는 레이어의 입력, 출력값 모두 형태를 지정해줘야 함\n",
    "  - `Linear(inputs, 8)`\n",
    "  - `ReLU()`\n",
    "  - `Linear(8, 16)`\n",
    "  - `ReLU()`\n",
    "  - `Linear(16, 32)`\n",
    "  - `ReLU()`\n",
    "  - `Linear(32, 64)` # 마지막에 softmax는 안 씀"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.714327Z",
     "start_time": "2025-11-06T11:18:55.708388Z"
    }
   },
   "source": [
    "#  또는 nn module로 선형 회귀\n",
    "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
    "# keras.layer.Dense 역할\n",
    "model = torch.nn.Linear(1, 1) # nn = Nueral Network \n",
    "print(model) # Keras의 model.summary()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1, out_features=1, bias=True)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.746559Z",
     "start_time": "2025-11-06T11:18:55.740165Z"
    }
   },
   "source": [
    "print(model.parameters()) # <generator object Module.parameters at 0x76680caada80> → Iteration 생성 객체 → list로 형변환해야 볼 수 있음\n",
    "print(list(model.parameters()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Module.parameters at 0x000002225DCE6340>\n",
      "[Parameter containing:\n",
      "tensor([[0.2125]], requires_grad=True), Parameter containing:\n",
      "tensor([0.5129], requires_grad=True)]\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:55.778502Z",
     "start_time": "2025-11-06T11:18:55.774078Z"
    }
   },
   "source": [
    "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델학습\n",
    "학습 과정을 살펴 보겠습니다.\n",
    "\n",
    "1. 에포크(Epoch):\n",
    "전체 훈련 데이터가 학습에 한 번 사용된 주기를 말합니다. 여기서는 총 2000번의 에포크(0 ~ 1999) 동안 학습을 수행하도록 설정했습니다.\n",
    "\n",
    "2. 예측(Hypothesis/Prediction):  \n",
    "모델은 입력 x에 가중치 W를 곱하고 편향 b를 더하여 예측값을 계산합니다. 이 예측값은 hypothesis에 저장됩니다.\n",
    "\n",
    "3. 비용 함수(Cost Function):  \n",
    "예측값 hypothesis와 실제값 y_train 간의 오차를 평균 제곱 오차(MSE) 로 계산하여 cost에 저장합니다.\n",
    "\n",
    "4. 최적화(Gradient Descent):  \n",
    "계산된 cost를 바탕으로 경사 하강법을 통해 모델의 가중치 W와 편향 b를 업데이트합니다.\n",
    "\n",
    "5. 로깅(Logging):  \n",
    "학습 진행 상황을 모니터링하기 위해 100 에포크마다 W, b 및 cost 값을 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.404875Z",
     "start_time": "2025-11-06T11:18:55.789597Z"
    }
   },
   "source": [
    "nb_epochs = 2000 # EPOCH 학습 횟수\n",
    "\n",
    "# Epoch : 전체 데이터를 1회 완독\n",
    "# 모델이 업데이트 되는 주기는 1 Batch\n",
    "# 일반적으로 1 Epoch != 1 Batch\n",
    "# 우리는 한 Epoch 당 여러 번의 Batch로 분할하여 학습\n",
    "# e.g 데이터 1000개, Batch_size=100이라면 100개짜리 묶음을 10번 순회 > 10번 업데이트\n",
    "# 1 Batch 학습 > 1 Step\n",
    "\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    \n",
    "    # 순전파 → H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)  # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        # 100번마다 로그 출력\n",
    "        print(\"Epoch {:4d}/{} Cost: {:.6f}\".format(epoch, nb_epochs, cost.item()))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 11.506186\n",
      "Epoch  100/2000 Cost: 0.105039\n",
      "Epoch  200/2000 Cost: 0.064908\n",
      "Epoch  300/2000 Cost: 0.040109\n",
      "Epoch  400/2000 Cost: 0.024785\n",
      "Epoch  500/2000 Cost: 0.015316\n",
      "Epoch  600/2000 Cost: 0.009464\n",
      "Epoch  700/2000 Cost: 0.005848\n",
      "Epoch  800/2000 Cost: 0.003614\n",
      "Epoch  900/2000 Cost: 0.002233\n",
      "Epoch 1000/2000 Cost: 0.001380\n",
      "Epoch 1100/2000 Cost: 0.000853\n",
      "Epoch 1200/2000 Cost: 0.000527\n",
      "Epoch 1300/2000 Cost: 0.000326\n",
      "Epoch 1400/2000 Cost: 0.000201\n",
      "Epoch 1500/2000 Cost: 0.000124\n",
      "Epoch 1600/2000 Cost: 0.000077\n",
      "Epoch 1700/2000 Cost: 0.000047\n",
      "Epoch 1800/2000 Cost: 0.000029\n",
      "Epoch 1900/2000 Cost: 0.000018\n",
      "Epoch 2000/2000 Cost: 0.000011\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 추론\n",
    "학습된 모델을 사용하여 새로운 데이터에 대한 예측을 수행해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.420446Z",
     "start_time": "2025-11-06T11:18:56.414388Z"
    }
   },
   "source": [
    "# 임의의 입력 4를 선언\n",
    "new_var = torch.FloatTensor([[4.0]])\n",
    "\n",
    "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var)  # forward 연산\n",
    "\n",
    "# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것\n",
    "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 4일 때의 예측값 : tensor([[7.9933]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 예제에서는 y = 2x 관계를 가지는 데이터로 모델을 학습시켰기 때문에, 입력값이 4일 때 예측값은 8에 가까운 값이 출력되어야 합니다. 이를 통해 모델이 정상적으로 학습되었음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 파라미터 확인\n",
    "PyTorch의 model.parameters() 메서드를 사용하면, 해당 모델의 모든 파라미터(가중치와 편향)를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.443482Z",
     "start_time": "2025-11-06T11:18:56.436133Z"
    }
   },
   "source": [
    "# list(model.parameters())\n",
    "for _ in model.parameters():\n",
    "    print(_)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1.9961]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.0088], requires_grad=True)\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Torch nn 모듈\n",
    "\n",
    "PyTorch의 신경망 모듈에 대해 알아봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.502420Z",
     "start_time": "2025-11-06T11:18:56.494784Z"
    }
   },
   "source": [
    "# 레이어 선언\n",
    "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "# kernel size - 1 만큼 덜 이동\n",
    "linear_layer = nn.Linear(in_features=128, out_features=10)\n",
    "relu = nn.ReLU() # Rectified Linear Unit의 줄임말\n",
    "maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "print(f\"Conv2d layer: {conv_layer}\")\n",
    "print(f\"Linear layer: {linear_layer}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d layer: Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "Linear layer: Linear(in_features=128, out_features=10, bias=True)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel 위치\n",
    "- Keras: `MNIST (28, 28, 1)` → Channel-last (B, H, W, C) 방식\n",
    "- PyTorch: `MNIST (1, 28, 28)` → Channel-first (B, C, H, W) 방식"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.549518Z",
     "start_time": "2025-11-06T11:18:56.539679Z"
    }
   },
   "source": [
    "# 더미 텐서로 레이어 테스트\n",
    "dummy_image = torch.randn(1, 3, 32, 32)  # Batch=1, Channel=3, Height=32, Width=32\n",
    "conv_output = conv_layer(dummy_image)\n",
    "print(f\"\\n입력 shape: {dummy_image.shape}\")\n",
    "print(f\"Conv 출력 shape: {conv_output.shape}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "입력 shape: torch.Size([1, 3, 32, 32])\n",
      "Conv 출력 shape: torch.Size([1, 16, 32, 32])\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 용어 정리\n",
    "- Layer(층): 노드와 노드 사이에서 계산을 실행하는 계층\n",
    "- 노드: 한 층을 통과(계산)한 후 결과를 취합한 각각의 집합\n",
    "- 커널: 이미지의 특징을 추출하는 작은 행렬 형태의 가중치 묶음을 의미. 종종 **필터(Filter)**와 같은 의미로 사용\n",
    "  - 3x3이 현재 가장 추천되는 커널 사이즈로 굳혀졌다.\n",
    "  - 커널 사이즈와 커널 수는 다른 개념이며, 한 번에 묶여서 실행되는 커널의 수가 커널 수가 된다.\n",
    "- CNN에서 특징별로 컨볼루션 필터가 featured maps를 만들고<br/>이를 특징마다 반복하며 최종 취합해 flatten layer를 만드는 일련의 과정을 backborn(척추), 이후 과정을 head(뇌)라고도 부른다.\n",
    "  - backborn은 이미지를 이해하는 과정, head는 학습 과정\n",
    "- 필터의 갯수는 관심갖는 필터링 대상(특징)만큼 늘어나며, out_channels가 곧 필터의 갯수다.\n",
    "- 필터마다 다가가는 갖는 정답이 다르므로, 여기에서 점차 도출해가는 최적의 가중치 또한 각각 다른 경우의 수가 나온다.\n",
    "- [참고](https://velog.io/@groovallstar/cnn)\n",
    "\n",
    "#### 퀴즈 - Conv2d layer에서 학습 가능한 매개변수 총 개수는 몇이 될까? (stride=1 기준)\n",
    "- 가중치 수\n",
    "$$\\text{Weight Count} = \\text{in\\_channels} \\times \\text{out\\_channels} \\times \\text{kernel\\_size} \\times \\text{kernel\\_size}$$\n",
    "-  편향수: 편향은 출력 채널의 개수만큼 존재\n",
    "$$\\text{Bias Count} = \\text{out\\_channels}$$\n",
    "- 총 학습 가능한 매개변수(Parameters)의 개수\n",
    "    ```\n",
    "    Conv2d layer: Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "    # (3 * 3 * 3 * 16) + 16 = 448\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.589147Z",
     "start_time": "2025-11-06T11:18:56.582571Z"
    }
   },
   "source": [
    "# 파라미터 확인\n",
    "print(f\"\\nConv layer의 파라미터:\")\n",
    "for name, param in conv_layer.named_parameters():\n",
    "    print(f\"  {name}: shape={param.shape}, requires_grad={param.requires_grad}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conv layer의 파라미터:\n",
      "  weight: shape=torch.Size([16, 3, 3, 3]), requires_grad=True\n",
      "  bias: shape=torch.Size([16]), requires_grad=True\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.626021Z",
     "start_time": "2025-11-06T11:18:56.619245Z"
    }
   },
   "source": [
    "# no_grad로 학습 방지\n",
    "print(f\"\\n학습 전 weight requires_grad: {conv_layer.weight.requires_grad}\")\n",
    "for param in conv_layer.parameters():\n",
    "    param.requires_grad = False\n",
    "print(f\"학습 방지 후 weight requires_grad: {conv_layer.weight.requires_grad}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "학습 전 weight requires_grad: True\n",
      "학습 방지 후 weight requires_grad: False\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.660942Z",
     "start_time": "2025-11-06T11:18:56.653967Z"
    }
   },
   "source": [
    "# 다시 학습 가능하게 설정\n",
    "for param in conv_layer.parameters():\n",
    "    param.requires_grad = True\n",
    "print(f\"다시 학습 가능하게 설정 후 weight requires_grad: {conv_layer.weight.requires_grad}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다시 학습 가능하게 설정 후 weight requires_grad: True\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 모델 만들기\n",
    "\n",
    "CNN 모델을 만드는 두 가지 방법을 알아봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.712761Z",
     "start_time": "2025-11-06T11:18:56.700806Z"
    }
   },
   "source": [
    "# 방법 1: Sequential\n",
    "sequential_model = nn.Sequential(                   # (3, 32, 32) 가정\n",
    "    nn.Conv2d(3, 32, kernel_size=3, padding=1),     # (32, 32, 32)\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),                                # (32, 16, 16)\n",
    "    nn.Conv2d(32, 64, kernel_size=3, padding=1),    # (64, 16, 16)\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),                                # (64, 8, 8)\n",
    "    nn.Flatten(),                                   # (64 * 8 * 8)\n",
    "    nn.Linear(64 * 8 * 8, 128),                     # (128,) # 1차원\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)                              # (10,)\n",
    ")\n",
    "\n",
    "print(sequential_model)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU()\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): ReLU()\n",
      "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=4096, out_features=128, bias=True)\n",
      "  (8): ReLU()\n",
      "  (9): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.757550Z",
     "start_time": "2025-11-06T11:18:56.743461Z"
    }
   },
   "source": [
    "# 방법 2: Subclassing (권장)\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # Convolutional layers # (3 x 32 x 32)\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)     # (32, 32, 32) → nn.MaxPool2d(2, 2) → (32, 16, 16)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)    # (64, 16, 16) → nn.MaxPool2d(2, 2) → (64, 8, 8)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)   # (128, 8, 8) → nn.MaxPool2d(2, 2) → (128, 4, 4)\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 4 * 4, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Conv block 1 Conv → ReLU → Max Pool\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # 32x32 -> 16x16\n",
    "        \n",
    "        # Conv block 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # 16x16 -> 8x8\n",
    "        \n",
    "        # Conv block 3\n",
    "        x = self.pool(F.relu(self.conv3(x)))  # 8x8 -> 4x4\n",
    "        \n",
    "        # Flatten → 배치 사이즈는 유지하고 나머지는 펴기\n",
    "        x = x.view(x.size(0), -1) # Batch, 128, 4, 4\n",
    "        \n",
    "        # FC layers → ReLU → Dropout → FC\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = CNNModel(num_classes=10)\n",
    "print(f\"\\nSubclassing Model:\\n{model}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subclassing Model:\n",
      "CNNModel(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=2048, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.790409Z",
     "start_time": "2025-11-06T11:18:56.783007Z"
    }
   },
   "source": [
    "# 모델 파라미터 수 계산\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\n전체 파라미터: {total_params:,}\")\n",
    "print(f\"학습 가능한 파라미터: {trainable_params:,}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "전체 파라미터: 620,362\n",
      "학습 가능한 파라미터: 620,362\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 순전파\n",
    "    - 데이터\n",
    "    - 모델\n",
    "2. 손실계산\n",
    "    - 손실함수\n",
    "    - 정답\n",
    "3. 역전파\n",
    "    - optimizer\n",
    "\n",
    "만약 일반적인 이미지(jpg, jpeg, png, svg, webp)를 다운받는다면? → 모델에 입력 불가\n",
    "\n",
    "Type -> torch.tensor\n",
    "크기 -> Resizing # 모델의 준비된 파라미터에 맞게 재조정\n",
    "정제 -> 정규화(Normalization/Scaling)\n",
    "오버피팅 방지 -> 증강(Augmentation)\n",
    "\n",
    "이미지/텍스트/오디오 서로 성격 다르므로 전처리 기법이 다름\n",
    "torch 각 모달리티를 위한 라이브러리를 제공함\n",
    "- torchvision\n",
    "- torchtexst (X 업데이트 중단. 허깅페이스에서 제공)\n",
    "- torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Optimizer와 Loss Function\n",
    "\n",
    "학습에 필요한 최적화 알고리즘과 손실 함수에 대해 알아봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.817940Z",
     "start_time": "2025-11-06T11:18:56.811948Z"
    }
   },
   "source": [
    "# Optimizer 설정\n",
    "optimizer_sgd = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # 1e-2\n",
    "optimizer_adam = optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer_adamw = optim.AdamW(model.parameters(), lr=0.01) # 크기가 큰 모델에서 사용 Transformer, Diffusion 학습법(크기가 큰 데서 사용)\n",
    "\n",
    "print(f\"SGD optimizer: {optimizer_sgd}\")\n",
    "print(f\"Adam optimizer: {optimizer_adam}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD optimizer: SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    differentiable: False\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0\n",
      ")\n",
      "Adam optimizer: Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    decoupled_weight_decay: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.01\n",
      "    maximize: False\n",
      "    weight_decay: 0\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.876123Z",
     "start_time": "2025-11-06T11:18:56.869452Z"
    }
   },
   "source": [
    "# Loss function\n",
    "criterion_ce = nn.CrossEntropyLoss() # sparse categorical 같은 것 없음 / Softmax 포함되어 있음\n",
    "criterion_mse = nn.MSELoss()\n",
    "\n",
    "print(f\"\\nCrossEntropyLoss: {criterion_ce}\")\n",
    "\n",
    "# Optimizer 사용 예시\n",
    "optimizer = optimizer_adam  # Adam 사용\n",
    "criterion = criterion_ce\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CrossEntropyLoss: CrossEntropyLoss()\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 데이터 준비 - CIFAR-10\n",
    "\n",
    "CIFAR-10 데이터셋을 다운로드하고 전처리합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:56.927395Z",
     "start_time": "2025-11-06T11:18:56.920312Z"
    }
   },
   "source": [
    "# Transform 정의\n",
    "transform_train = transforms.Compose([\n",
    "    # 증강기법들(Augumentation)\n",
    "    transforms.RandomCrop(32, padding=4),   # 무작위 자르기 및 확대\n",
    "    transforms.RandomHorizontalFlip(),      # 무작위 좌우 대칭\n",
    "    # 모델에 입력하기 위한 정제 과정\n",
    "    transforms.ToTensor(),                  # PIL.Image -> torch.tensor 형식으로 변환\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))    # (R, G, B) 표준정규화 \n",
    "    # 표준화 공식: (x - 평균) / 표준편차\n",
    "])\n",
    "\n",
    "# 테스트 단계에서는 증강 과정 불필요\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.465468Z",
     "start_time": "2025-11-06T11:18:56.946438Z"
    }
   },
   "source": [
    "# CIFAR-10 다운로드\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform_train\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', \n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform_test\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.482945Z",
     "start_time": "2025-11-06T11:18:58.476122Z"
    }
   },
   "source": [
    "type(full_train_dataset) # sklearn.model_selection.train_test_split 사용 불가"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torchvision.datasets.cifar.CIFAR10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.505919Z",
     "start_time": "2025-11-06T11:18:58.497430Z"
    }
   },
   "source": [
    "# 데이터 분할: Train/Validation\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.530656Z",
     "start_time": "2025-11-06T11:18:58.525030Z"
    }
   },
   "source": [
    "# Validation dataset에 test transform 적용\n",
    "val_dataset.dataset.transform = transform_test"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.550433Z",
     "start_time": "2025-11-06T11:18:58.544640Z"
    }
   },
   "source": [
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 40000\n",
      "Validation dataset size: 10000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.592069Z",
     "start_time": "2025-11-06T11:18:58.587230Z"
    }
   },
   "source": [
    "# 클래스 이름\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', \n",
    "           'dog', 'frog', 'horse', 'ship', 'truck')\n"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.617262Z",
     "start_time": "2025-11-06T11:18:58.608193Z"
    }
   },
   "source": [
    "dir(train_dataset)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__firstlineno__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getitems__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__static_attributes__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'dataset',\n",
       " 'indices']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.647854Z",
     "start_time": "2025-11-06T11:18:58.636321Z"
    }
   },
   "source": [
    "# dir(train_dataset.dataset)\n",
    "# x_train\n",
    "train_dataset.dataset.data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]],\n",
       "\n",
       "\n",
       "       [[[154, 177, 187],\n",
       "         [126, 137, 136],\n",
       "         [105, 104,  95],\n",
       "         ...,\n",
       "         [ 91,  95,  71],\n",
       "         [ 87,  90,  71],\n",
       "         [ 79,  81,  70]],\n",
       "\n",
       "        [[140, 160, 169],\n",
       "         [145, 153, 154],\n",
       "         [125, 125, 118],\n",
       "         ...,\n",
       "         [ 96,  99,  78],\n",
       "         [ 77,  80,  62],\n",
       "         [ 71,  73,  61]],\n",
       "\n",
       "        [[140, 155, 164],\n",
       "         [139, 146, 149],\n",
       "         [115, 115, 112],\n",
       "         ...,\n",
       "         [ 79,  82,  64],\n",
       "         [ 68,  70,  55],\n",
       "         [ 67,  69,  55]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[175, 167, 166],\n",
       "         [156, 154, 160],\n",
       "         [154, 160, 170],\n",
       "         ...,\n",
       "         [ 42,  34,  36],\n",
       "         [ 61,  53,  57],\n",
       "         [ 93,  83,  91]],\n",
       "\n",
       "        [[165, 154, 128],\n",
       "         [156, 152, 130],\n",
       "         [159, 161, 142],\n",
       "         ...,\n",
       "         [103,  93,  96],\n",
       "         [123, 114, 120],\n",
       "         [131, 121, 131]],\n",
       "\n",
       "        [[163, 148, 120],\n",
       "         [158, 148, 122],\n",
       "         [163, 156, 133],\n",
       "         ...,\n",
       "         [143, 133, 139],\n",
       "         [143, 134, 142],\n",
       "         [143, 133, 144]]],\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         ...,\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253],\n",
       "         [253, 253, 253]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         ...,\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[113, 120, 112],\n",
       "         [111, 118, 111],\n",
       "         [105, 112, 106],\n",
       "         ...,\n",
       "         [ 72,  81,  80],\n",
       "         [ 72,  80,  79],\n",
       "         [ 72,  80,  79]],\n",
       "\n",
       "        [[111, 118, 110],\n",
       "         [104, 111, 104],\n",
       "         [ 99, 106,  98],\n",
       "         ...,\n",
       "         [ 68,  75,  73],\n",
       "         [ 70,  76,  75],\n",
       "         [ 78,  84,  82]],\n",
       "\n",
       "        [[106, 113, 105],\n",
       "         [ 99, 106,  98],\n",
       "         [ 95, 102,  94],\n",
       "         ...,\n",
       "         [ 78,  85,  83],\n",
       "         [ 79,  85,  83],\n",
       "         [ 80,  86,  84]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 35, 178, 235],\n",
       "         [ 40, 176, 239],\n",
       "         [ 42, 176, 241],\n",
       "         ...,\n",
       "         [ 99, 177, 219],\n",
       "         [ 79, 147, 197],\n",
       "         [ 89, 148, 189]],\n",
       "\n",
       "        [[ 57, 182, 234],\n",
       "         [ 44, 184, 250],\n",
       "         [ 50, 183, 240],\n",
       "         ...,\n",
       "         [156, 182, 200],\n",
       "         [141, 177, 206],\n",
       "         [116, 149, 175]],\n",
       "\n",
       "        [[ 98, 197, 237],\n",
       "         [ 64, 189, 252],\n",
       "         [ 69, 192, 245],\n",
       "         ...,\n",
       "         [188, 195, 206],\n",
       "         [119, 135, 147],\n",
       "         [ 61,  79,  90]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 73,  79,  77],\n",
       "         [ 53,  63,  68],\n",
       "         [ 54,  68,  80],\n",
       "         ...,\n",
       "         [ 17,  40,  64],\n",
       "         [ 21,  36,  51],\n",
       "         [ 33,  48,  49]],\n",
       "\n",
       "        [[ 61,  68,  75],\n",
       "         [ 55,  70,  86],\n",
       "         [ 57,  79, 103],\n",
       "         ...,\n",
       "         [ 24,  48,  72],\n",
       "         [ 17,  35,  53],\n",
       "         [  7,  23,  32]],\n",
       "\n",
       "        [[ 44,  56,  73],\n",
       "         [ 46,  66,  88],\n",
       "         [ 49,  77, 105],\n",
       "         ...,\n",
       "         [ 27,  52,  77],\n",
       "         [ 21,  43,  66],\n",
       "         [ 12,  31,  50]]],\n",
       "\n",
       "\n",
       "       [[[189, 211, 240],\n",
       "         [186, 208, 236],\n",
       "         [185, 207, 235],\n",
       "         ...,\n",
       "         [175, 195, 224],\n",
       "         [172, 194, 222],\n",
       "         [169, 194, 220]],\n",
       "\n",
       "        [[194, 210, 239],\n",
       "         [191, 207, 236],\n",
       "         [190, 206, 235],\n",
       "         ...,\n",
       "         [173, 192, 220],\n",
       "         [171, 191, 218],\n",
       "         [167, 190, 216]],\n",
       "\n",
       "        [[208, 219, 244],\n",
       "         [205, 216, 240],\n",
       "         [204, 215, 239],\n",
       "         ...,\n",
       "         [175, 191, 217],\n",
       "         [172, 190, 216],\n",
       "         [169, 191, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[207, 199, 181],\n",
       "         [203, 195, 175],\n",
       "         [203, 196, 173],\n",
       "         ...,\n",
       "         [135, 132, 127],\n",
       "         [162, 158, 150],\n",
       "         [168, 163, 151]],\n",
       "\n",
       "        [[198, 190, 170],\n",
       "         [189, 181, 159],\n",
       "         [180, 172, 147],\n",
       "         ...,\n",
       "         [178, 171, 160],\n",
       "         [175, 169, 156],\n",
       "         [175, 169, 154]],\n",
       "\n",
       "        [[198, 189, 173],\n",
       "         [189, 181, 162],\n",
       "         [178, 170, 149],\n",
       "         ...,\n",
       "         [195, 184, 169],\n",
       "         [196, 189, 171],\n",
       "         [195, 190, 171]]],\n",
       "\n",
       "\n",
       "       [[[229, 229, 239],\n",
       "         [236, 237, 247],\n",
       "         [234, 236, 247],\n",
       "         ...,\n",
       "         [217, 219, 233],\n",
       "         [221, 223, 234],\n",
       "         [222, 223, 233]],\n",
       "\n",
       "        [[222, 221, 229],\n",
       "         [239, 239, 249],\n",
       "         [233, 234, 246],\n",
       "         ...,\n",
       "         [223, 223, 236],\n",
       "         [227, 228, 238],\n",
       "         [210, 211, 220]],\n",
       "\n",
       "        [[213, 206, 211],\n",
       "         [234, 232, 239],\n",
       "         [231, 233, 244],\n",
       "         ...,\n",
       "         [220, 220, 232],\n",
       "         [220, 219, 232],\n",
       "         [202, 203, 215]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[150, 143, 135],\n",
       "         [140, 135, 127],\n",
       "         [132, 127, 120],\n",
       "         ...,\n",
       "         [224, 222, 218],\n",
       "         [230, 228, 225],\n",
       "         [241, 241, 238]],\n",
       "\n",
       "        [[137, 132, 126],\n",
       "         [130, 127, 120],\n",
       "         [125, 121, 115],\n",
       "         ...,\n",
       "         [181, 180, 178],\n",
       "         [202, 201, 198],\n",
       "         [212, 211, 207]],\n",
       "\n",
       "        [[122, 119, 114],\n",
       "         [118, 116, 110],\n",
       "         [120, 116, 111],\n",
       "         ...,\n",
       "         [179, 177, 173],\n",
       "         [164, 164, 162],\n",
       "         [163, 163, 161]]]], shape=(50000, 32, 32, 3), dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.726434Z",
     "start_time": "2025-11-06T11:18:58.710063Z"
    }
   },
   "source": [
    "# y_train\n",
    "train_dataset.dataset.targets"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 9,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 1,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 6,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 8,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 5,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 8,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 6,\n",
       " 1,\n",
       " 9,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 8,\n",
       " 5,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 0,\n",
       " 9,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 9,\n",
       " 9,\n",
       " 1,\n",
       " 0,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 2,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 8,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 7,\n",
       " 9,\n",
       " 1,\n",
       " 5,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 1,\n",
       " 0,\n",
       " 3,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 6,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 0,\n",
       " 8,\n",
       " 9,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 1,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 9,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 4,\n",
       " 8,\n",
       " 1,\n",
       " 8,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 1,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 4,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 9,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 8,\n",
       " 1,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 1,\n",
       " 8,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 8,\n",
       " 7,\n",
       " 1,\n",
       " 9,\n",
       " 1,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 6,\n",
       " 8,\n",
       " 1,\n",
       " 9,\n",
       " 7,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 9,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 0,\n",
       " 8,\n",
       " 0,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 9,\n",
       " 9,\n",
       " 7,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 9,\n",
       " 1,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 9,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 9,\n",
       " 6,\n",
       " 9,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 9,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 9,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 0,\n",
       " 7,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 4,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 0,\n",
       " 1,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 9,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 5,\n",
       " 0,\n",
       " 8,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 0,\n",
       " 9,\n",
       " 5,\n",
       " 5,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 9,\n",
       " 4,\n",
       " 0,\n",
       " 8,\n",
       " 5,\n",
       " 9,\n",
       " 9,\n",
       " 6,\n",
       " 7,\n",
       " 1,\n",
       " 8,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 0,\n",
       " 0,\n",
       " 5,\n",
       " 3,\n",
       " 8,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 9,\n",
       " 3,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 7,\n",
       " 9,\n",
       " 0,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 8,\n",
       " 0,\n",
       " 5,\n",
       " 5,\n",
       " 1,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 0,\n",
       " 1,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 1,\n",
       " 1,\n",
       " 7,\n",
       " 0,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 1,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 0,\n",
       " 9,\n",
       " 4,\n",
       " 3,\n",
       " 8,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 9,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 9,\n",
       " 3,\n",
       " 9,\n",
       " 9,\n",
       " 2,\n",
       " 9,\n",
       " 4,\n",
       " 8,\n",
       " 2,\n",
       " 9,\n",
       " 8,\n",
       " 8,\n",
       " 1,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 8,\n",
       " 0,\n",
       " 6,\n",
       " 4,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 5,\n",
       " 8,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 9,\n",
       " 7,\n",
       " 1,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 1,\n",
       " 6,\n",
       " 0,\n",
       " 4,\n",
       " 0,\n",
       " 3,\n",
       " 1,\n",
       " 8,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 1,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 4,\n",
       " 7,\n",
       " 9,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 8,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 1,\n",
       " 2,\n",
       " 9,\n",
       " 0,\n",
       " 4,\n",
       " 8,\n",
       " 7,\n",
       " 3,\n",
       " 9,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 0,\n",
       " 2,\n",
       " 4,\n",
       " 1,\n",
       " 1,\n",
       " 4,\n",
       " 1,\n",
       " 5,\n",
       " 4,\n",
       " 0,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 8,\n",
       " 5,\n",
       " 0,\n",
       " 2,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 1,\n",
       " 3,\n",
       " 5,\n",
       " ...]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.768138Z",
     "start_time": "2025-11-06T11:18:58.759651Z"
    }
   },
   "source": [
    "print(train_dataset.dataset.data[0])\n",
    "print(train_dataset.dataset.targets[0])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 59  62  63]\n",
      "  [ 43  46  45]\n",
      "  [ 50  48  43]\n",
      "  ...\n",
      "  [158 132 108]\n",
      "  [152 125 102]\n",
      "  [148 124 103]]\n",
      "\n",
      " [[ 16  20  20]\n",
      "  [  0   0   0]\n",
      "  [ 18   8   0]\n",
      "  ...\n",
      "  [123  88  55]\n",
      "  [119  83  50]\n",
      "  [122  87  57]]\n",
      "\n",
      " [[ 25  24  21]\n",
      "  [ 16   7   0]\n",
      "  [ 49  27   8]\n",
      "  ...\n",
      "  [118  84  50]\n",
      "  [120  84  50]\n",
      "  [109  73  42]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[208 170  96]\n",
      "  [201 153  34]\n",
      "  [198 161  26]\n",
      "  ...\n",
      "  [160 133  70]\n",
      "  [ 56  31   7]\n",
      "  [ 53  34  20]]\n",
      "\n",
      " [[180 139  96]\n",
      "  [173 123  42]\n",
      "  [186 144  30]\n",
      "  ...\n",
      "  [184 148  94]\n",
      "  [ 97  62  34]\n",
      "  [ 83  53  34]]\n",
      "\n",
      " [[177 144 116]\n",
      "  [168 129  94]\n",
      "  [179 142  87]\n",
      "  ...\n",
      "  [216 184 140]\n",
      "  [151 118  84]\n",
      "  [123  92  72]]]\n",
      "6\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-06T11:18:58.825489Z",
     "start_time": "2025-11-06T11:18:58.816020Z"
    }
   },
   "source": [
    "print(train_dataset.dataset.data[0].shape)\n",
    "type(train_dataset.dataset.data)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-06T11:18:58.888032Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_train = train_dataset.dataset.data\n",
    "y_train = train_dataset.dataset.targets\n",
    "\n",
    "# plt.imshow(x_train[0])\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15, 15))\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        idx = i * 5 + j\n",
    "        axes[i, j].imshow(x_train[idx])\n",
    "        axes[i, j].axis(\"off\")\n",
    "        axes[i, j].set_title(classes[y_train[idx]])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습\n",
    "1. Data 다운 & 저장 → Storage\n",
    "2. 전처리 → CPU\n",
    "    - 데이터 표준화\n",
    "        - Tensor 자료형 변형\n",
    "        - X - Y 관계 지정\n",
    "        - 데이터 동일 양식\n",
    "    - Batch 구성\n",
    "3. 학습 → GPU\n",
    "    - 순전파\n",
    "    - 손실계산\n",
    "    - 역전파\n",
    "\n",
    "GPU의 학습 효율을 최대화하려면 필요한 데이터를 빠르게 찾아야 하고<br/>\n",
    "한 번에 얼만큼 불러와 어떤 처리를 할지 등등을 먼저 지정해줘야 한다.<br/>\n",
    "아래는 DataLoader가 효율적으로 데이터를 불러올 수 있도록 커스덤 데이터셋을 만드는 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 커스텀 데이터셋 클래스 예시\n",
    "\n",
    "커스텀 데이터셋을 만드는 방법을 알아봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class CustomCIFAR10(Dataset):\n",
    "    \"\"\"\n",
    "    커스텀 데이터셋 클래스 예시\n",
    "    실제로는 위의 torchvision.datasets.CIFAR10을 사용하지만,\n",
    "    커스텀 데이터셋을 만드는 방법을 보여주기 위한 예시입니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform # 이미지 변환 기법 방식\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.data[idx]\n",
    "        label = self.targets[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "train_dataset.__len__()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x, y = train_dataset.__getitem__(0)\n",
    "print(x, y)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(x.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. DataLoader\n",
    "\n",
    "데이터를 배치 단위로 로드하는 DataLoader를 설정합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "batch_size = 32 # 128\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,          # 어디에서 데이터를 가져와 어떻게 처리할 것인지\n",
    "    batch_size=batch_size,  # 한 배치를 몇 개 데이터로 구성할 것인지\n",
    "    shuffle=True,           # 섞을지 말지\n",
    "    num_workers=2           # CPU에서 수행하는 작업이므로, CPU core를 얼마나 할당할지\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\") # Batch들의 수\n",
    "print(f\"Validation batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "test_dataset.__len__() / batch_size"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x = iter(range(10)) # 이터레이터로 변환 → next() 사용 가능"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 반복 실행마다 다음 요소 출력\n",
    "next(x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 첫 번째 배치만 꺼내 살펴보기\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break\n",
    "\n",
    "# torch.Size([batch, channel, height, width]) torch.Size([정답(y) 수])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 샘플 배치 확인\n",
    "sample_batch = next(iter(train_loader)) # 이터레이션 처리\n",
    "sample_images, sample_labels = sample_batch\n",
    "print(f\"\\nSample batch - Images shape: {sample_images.shape}\")\n",
    "print(f\"Sample batch - Labels shape: {sample_labels.shape}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 학습 및 평가 함수\n",
    "\n",
    "모델 학습과 평가를 위한 함수들을 정의합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "#tqdm → 진행도바 그려주는 라이브러리\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train_epoch(model, loader, criterion, optimizer, device):\n",
    "    \"\"\"한 에포크 학습\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        # 각 이미지/라벨 배치를 GPU가 있을 경우 GPU로 이동\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass: 순전파\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images) # 예측값\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels) # 손실함수(예측값, 정답)\n",
    "        \n",
    "        # Backward pass: 역전파\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 통계\n",
    "        running_loss += loss.item() # 손실 총합 = 에포크 손실\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item() # 맞춘 횟수 → 정확도 계산에 사용\n",
    "        \n",
    "        # 프로그레스 바 업데이트\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss / (pbar.n + 1):.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def validate_epoch(model, loader, criterion, device):\n",
    "    \"\"\"한 에포크 검증\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    # Gradient 계산을 하지 않으면서 처리 → GPU 메모리 낭비 방지\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc='Validation')\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            # 순전파\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels) # 손실 계산\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss / (pbar.n + 1):.4f}',\n",
    "                'acc': f'{100. * correct / total:.2f}%'\n",
    "            })\n",
    "    \n",
    "    epoch_loss = running_loss / len(loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, \n",
    "                num_epochs, device, best_model_path='best_model.pth'):\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "    \n",
    "    best_val_loss = float('inf') # 무한\n",
    "    best_model_wts = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # 학습 1250 번\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # 검증 313번\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # 히스토리 저장\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        \n",
    "        # best val_loss 모델 저장\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_wts = model.state_dict()\n",
    "            torch.save(best_model_wts, best_model_path)\n",
    "            print(f'>> Best model saved! val_loss: {val_loss:.4f}')\n",
    "        \n",
    "        # 결과 출력\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "        \n",
    "    return history\n",
    "\n",
    "print(\"전체 학습 루프 함수 정의 완료\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 모델 학습 실행\n",
    "\n",
    "CNN 모델을 학습시킵니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 모델 초기화\n",
    "model = CNNModel(num_classes=len(classes)).to(device) # .to(device)로 모델 위치 일치시키기\n",
    "\n",
    "# Optimizer와 Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "# 학습 실행\n",
    "num_epochs = 20\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=num_epochs,\n",
    "    device=device,\n",
    "    best_model_path='best_model.pth'\n",
    ")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 학습 곡선 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history['train_loss'], label='Train Loss')\n",
    "axes[0].plot(history['val_loss'], label='Val Loss')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(history['train_acc'], label='Train Acc')\n",
    "axes[1].plot(history['val_acc'], label='Val Acc')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Accuracy (%)')\n",
    "axes[1].set_title('Training and Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_history.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"Training history saved to 'training_history.png'\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. 테스트\n",
    "\n",
    "학습된 모델을 테스트 데이터로 평가합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# best model을 불러오는 코드\n",
    "best_model = torch.load('best_model.pth', map_location=device)\n",
    "model.load_state_dict(best_model)\n",
    "print(\"Best model loaded from 'best_model.pth'\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def test_model(model, test_loader, device):\n",
    "    \"\"\"테스트 데이터로 모델 평가\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # 클래스별 정확도 계산을 위한 변수\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc='Testing'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # 클래스별 정확도\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(len(labels)):\n",
    "                label = labels[i]\n",
    "                class_correct[label] += c[i].item()\n",
    "                class_total[label] += 1\n",
    "    \n",
    "    # 전체 정확도\n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'\\nTest Accuracy: {accuracy:.2f}%')\n",
    "    \n",
    "    # 클래스별 정확도\n",
    "    print('\\nClass-wise Accuracy:')\n",
    "    for i in range(10):\n",
    "        class_acc = 100 * class_correct[i] / class_total[i]\n",
    "        print(f'{classes[i]:>10s}: {class_acc:.2f}%')\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "test_accuracy = test_model(model, test_loader, device)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Pretrained 모델 불러오기\n",
    "\n",
    "사전 훈련된 모델을 불러오는 방법을 알아봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# torchvision에서 모델 불러오기\n",
    "print(\"[torchvision models]\")\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "print(f\"ResNet18 loaded: {type(resnet18)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(resnet18)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 마지막 레이어 수정 (CIFAR-10은 10개 클래스)\n",
    "num_features = resnet18.fc.in_features # 512라는 숫자를 가져오는 방법 (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
    "resnet18.fc = nn.Linear(in_features=num_features, out_features=len(classes)) # in 512 out 10\n",
    "print(f\"Modified final layer for 10 classes\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# timm에서 모델 불러오기\n",
    "print(\"\\n[timm models]\")\n",
    "efficientnet = timm.create_model('efficientnet_b0', pretrained=True, num_classes=10)\n",
    "print(f\"EfficientNet-B0 loaded: {type(efficientnet)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# timm에서 사용 가능한 모델 확인 (처음 10개만)\n",
    "available_models = timm.list_models(pretrained=True)[:10]\n",
    "print(f\"\\nAvailable pretrained models (first 10): {available_models}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. 전이학습 (Transfer Learning)\n",
    "\n",
    "사전 훈련된 모델을 활용한 전이학습 방법을 알아봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ResNet18로 전이학습 예시\n",
    "model_transfer = models.resnet18(pretrained=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 방법 1: 모든 레이어 동결 (Feature Extractor로 사용)\n",
    "print(\"[방법 1] Feature Extractor - 모든 레이어 동결\")\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False # 기존 모델의 파라미터 동결 → 전이학습 과정에서 모델의 기존 학습된 파라미터가 영향받지 않도록 조치\n",
    "\n",
    "# 마지막 레이어만 학습 가능하게 설정\n",
    "num_features = model_transfer.fc.in_features\n",
    "model_transfer.fc = nn.Linear(num_features, 10) # requires_grad = True → 새로 붙였기 때문\n",
    "\n",
    "# 학습 가능한 파라미터만 optimizer에 전달\n",
    "optimizer_transfer = optim.Adam(model_transfer.fc.parameters(), lr=0.001)\n",
    "\n",
    "trainable_params_1 = sum(p.numel() for p in model_transfer.parameters() if p.requires_grad)\n",
    "print(f\"학습 가능한 파라미터 수: {trainable_params_1:,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "resnet18"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 방법 2: 일부 레이어만 학습 (Fine-tuning)\n",
    "print(\"\\n[방법 2] Fine-tuning - 마지막 몇 개 레이어만 학습\")\n",
    "model_transfer2 = models.resnet18(pretrained=True)\n",
    "\n",
    "# 처음 레이어들은 동결\n",
    "for name, param in model_transfer2.named_parameters():\n",
    "    if 'layer4' not in name and 'fc' not in name:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# 마지막 레이어 수정\n",
    "model_transfer2.fc = nn.Linear(in_features=model_transfer2.fc.in_features, out_features=len(classes))\n",
    "\n",
    "# 학습 가능한 파라미터만 optimizer에 전달\n",
    "optimizer_transfer2 = optim.Adam(\n",
    "    filter(lambda p: p.requires_grad, model_transfer2.parameters()), \n",
    "    lr=0.001\n",
    ")\n",
    "\n",
    "trainable_params_2 = sum(p.numel() for p in model_transfer2.parameters() if p.requires_grad)\n",
    "print(f\"학습 가능한 파라미터 수: {trainable_params_2:,}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 방법 3: 전체 모델 Fine-tuning (작은 learning rate 사용)\n",
    "print(\"\\n[방법 3] Full Fine-tuning - 전체 모델 학습 (작은 LR)\")\n",
    "model_transfer3 = models.resnet18(pretrained=True)\n",
    "model_transfer3.fc = nn.Linear(model_transfer3.fc.in_features, 10)\n",
    "\n",
    "# Differential learning rate: Backbone은 작은 LR, 새 레이어는 큰 LR\n",
    "optimizer_transfer3 = optim.Adam([\n",
    "    {'params': model_transfer3.layer4.parameters(), 'lr': 1e-4},\n",
    "    {'params': model_transfer3.fc.parameters(), 'lr': 1e-3}\n",
    "])\n",
    "\n",
    "print(f\"Backbone LR: 1e-4, New layer LR: 1e-3\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 전이학습 모델로 간단히 학습 (3 에포크만)\n",
    "print(\"\\n전이학습 모델 학습 시작 (3 epochs)...\")\n",
    "model_transfer = model_transfer.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(3):\n",
    "    print(f'\\nEpoch {epoch+1}/3')\n",
    "    train_loss, train_acc = train_epoch(\n",
    "        model_transfer, train_loader, criterion, optimizer_transfer, device\n",
    "    )\n",
    "    val_loss, val_acc = validate_epoch(\n",
    "        model_transfer, val_loader, criterion, device\n",
    "    )\n",
    "    print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "    print(f'Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. 모델 저장 및 불러오기\n",
    "\n",
    "학습된 모델을 저장하고 불러오는 방법을 알아봅니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 모델 저장\n",
    "torch.save(model.state_dict(), 'cifar10_cnn_model.pth')\n",
    "print(\"모델 가중치 저장 완료: cifar10_cnn_model.pth\")\n",
    "\n",
    "# 전체 모델 저장 (권장하지 않음, 하지만 가능함)\n",
    "torch.save(model, 'cifar10_cnn_full_model.pth')\n",
    "print(\"전체 모델 저장 완료: cifar10_cnn_full_model.pth\")\n",
    "\n",
    "# 모델 불러오기\n",
    "loaded_model = CNNModel(num_classes=10)\n",
    "loaded_model.load_state_dict(torch.load('cifar10_cnn_model.pth'))\n",
    "loaded_model = loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "print(\"\\n모델 가중치 불러오기 완료\")\n",
    "\n",
    "# 체크포인트 저장 (optimizer 상태 포함)\n",
    "checkpoint = {\n",
    "    'epoch': num_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'history': history\n",
    "}\n",
    "torch.save(checkpoint, 'checkpoint.pth')\n",
    "print(\"체크포인트 저장 완료: checkpoint.pth\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 추론 예시\n",
    "\n",
    "학습된 모델을 사용하여 새로운 이미지에 대한 예측을 수행합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# 테스트 이미지 하나 가져오기\n",
    "sample_image, sample_label = test_dataset[0]\n",
    "sample_image_batch = sample_image.unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "\n",
    "# 추론\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(sample_image_batch)\n",
    "    probabilities = F.softmax(output, dim=1)\n",
    "    predicted_class = output.argmax(dim=1).item()\n",
    "    confidence = probabilities[0][predicted_class].item()\n",
    "\n",
    "print(f\"실제 클래스: {classes[sample_label]}\")\n",
    "print(f\"예측 클래스: {classes[predicted_class]}\")\n",
    "print(f\"신뢰도: {confidence * 100:.2f}%\")\n",
    "\n",
    "# Top-5 예측\n",
    "top5_prob, top5_classes = torch.topk(probabilities, 5)\n",
    "print(\"\\nTop-5 예측:\")\n",
    "for i in range(5):\n",
    "    print(f\"{i+1}. {classes[top5_classes[0][i]]}: {top5_prob[0][i].item() * 100:.2f}%\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
